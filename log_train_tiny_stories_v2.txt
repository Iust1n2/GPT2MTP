INFO:root:Training with args: TrainingArgs(model_config=GPT2MTPConfig(d_vocab=50257, n_ctx=256, n_layers=2, n_heads=4, d_model=256, d_mlp=1024, d_head=64, d_vocab_out=50257, attn_scale=8.0, use_attn_result=False, use_split_qkv_input=False, n_key_value_heads=None, dropout=0.0, bias=True, dtype=torch.float32, post_embedding_ln=False, act_function='gelu', rotary_adjacent_pairs=False, rotary_dim=64, rotary_base=10000, use_NTK_by_parts_rope=False, NTK_by_parts_low_freq_factor=1.0, NTK_by_parts_high_freq_factor=4.0, NTK_by_parts_factor=8.0, mtp_heads=4, loss_type='multi_token', tokenizer_name='gpt2', default_prepend_bos=True, device='cuda', n_devices=1, iniitalizer_range=-1.0), dataset_config=DatasetConfig(data_dir='data/tiny_stories_v2/', split='train', batch_size=32, block_size=256, n_future=4, device='cuda'), data_dir='data/tiny_stories_v2/', save_dir='checkpoints/tiny_stories_v2/', init_from='resume', always_save_checkpoint=True, eval_only=False, eval_interval=100, eval_iters=50, eval_ngrams=False, n_future=4, batch_size=32, gradient_accumulation_steps=32, max_iters=2080, lr_decay_iters=2080, max_lr=0.0003, decay_lr=True, warmup_steps=50, min_lr=3e-05, weight_decay=0.005, betas=(0.9, 0.98), grad_clip=1.0, log_interval=50, device='cuda', dtype='bfloat16', compile=True)
INFO:root:Tokens per step will be: 262,144
INFO:root:Resuming training from checkpoints/tiny_stories_v2/checkpoint_step_1000.pt
INFO:root:Resumed Training - Step 1000, Learning Rate: 0.00016506
INFO:root:Compiling the model... (takes a ~minute)
INFO:root:Compilation complete.
INFO:root:Entering training loop...
INFO:root:Step 1000, Learning Rate: 0.00016506349581205085
W0318 09:02:11.802000 629432 torch/_dynamo/convert_frame.py:906] [4/8] torch._dynamo hit config.cache_size_limit (8)
W0318 09:02:11.802000 629432 torch/_dynamo/convert_frame.py:906] [4/8]    function: 'full_hook' (/home/iustin/.conda/envs/mtp/lib/python3.12/site-packages/transformer_lens/hook_points.py:100)
W0318 09:02:11.802000 629432 torch/_dynamo/convert_frame.py:906] [4/8]    last reason: 4/0: not L['hook'].func.__closure__[0].cell_contents             
W0318 09:02:11.802000 629432 torch/_dynamo/convert_frame.py:906] [4/8] To log all recompilation reasons, use TORCH_LOGS="recompiles".
W0318 09:02:11.802000 629432 torch/_dynamo/convert_frame.py:906] [4/8] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.
INFO:root:Eval Step 1000 across 50 batches (0.8M Tokens): Train Loss 10.7063, Val Loss 10.7114
INFO:root:Entering gradient accumulation loop for step 1000
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0238, Head Loss: 0.1795
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0307, Head Loss: 0.1462
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0367, Head Loss: 0.1557
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0409, Head Loss: 0.1576
INFO:root:Final accum gradient norm after all heads: 0.0409, Total Loss: 20.4503, Average Loss: 5.1126
INFO:root:Step 1000: Loss 5.11, Norm: 2.0936, Time: 29.96s, Tokens Seen: 251.9M
INFO:root:Predicted n-gram: ['redients', 'led', ',', ' upon'], Target n-gram: ['.', ' The', ' ants', ' were']
INFO:root:Predicted n-gram: ['>', ' Karachi', '<|endoftext|>', 'events'], Target n-gram: [' fun', ' and', ' special', '.']
INFO:root:Predicted n-gram: [' calmed', 'uden', ' bragging', ' taco'], Target n-gram: [' she', ' saw', ' a', ' little']
INFO:root:Predicted n-gram: ['ş', ' day', ',', ' upon'], Target n-gram: [' and', ' the', ' bear', ' had']
INFO:root:Predicted n-gram: ['.', 'illin', ' rivals', 'events'], Target n-gram: [' need', ' to', ' share', '."']
INFO:root:Predicted n-gram: ['of', 'of', ' and', 'end'], Target n-gram: [' they', ' found', ' food', ' for']
INFO:root:Predicted n-gram: ['.', '<|endoftext|>', ' there', ' was'], Target n-gram: ['.', '\n', 'Jack', ' gave']
INFO:root:Predicted n-gram: ['.', 'illin', ' there', 'events'], Target n-gram: [' out', ' the', ' window', ' and']
INFO:root:Predicted n-gram: ['.', 'uden', ' >=', ' liaison'], Target n-gram: [' The', ' bunny', ' smiled', ' and']
INFO:root:Predicted n-gram: [' Regulation', ' Announce', 'acts', ' manga'], Target n-gram: ['<', '|', 'end', 'of']
INFO:root:Predicted n-gram: [' flowers', '>', 'Don', '>'], Target n-gram: [' down', ' from', ' the', ' sky']
INFO:root:Predicted n-gram: ['ş', ' day', ',', ' upon'], Target n-gram: [' knife', ' and', ' a', ' plate']
INFO:root:Predicted n-gram: [' small', ' amount', 'angering', ' liaison'], Target n-gram: ['.', ' But', ' then', ',']
INFO:root:Predicted n-gram: [' and', ' ItemLevel', '<|endoftext|>', '010'], Target n-gram: [' and', ' couldn', "'t", ' wait']
INFO:root:Predicted n-gram: [' small', ' amount', 'angering', ' liaison'], Target n-gram: ['|', 'end', 'of', 'text']
INFO:root:Predicted n-gram: ['>', '>', '.', '>'], Target n-gram: [' colors', '.', ' Kids', ' loved']
INFO:root:Predicted n-gram: [' Regulation', ' Announce', 'acts', ' manga'], Target n-gram: [' you', ' accept', ' to', ' help']
INFO:root:Predicted n-gram: ['|', '"', 'of', ' looked'], Target n-gram: ['<|endoftext|>', 'Once', ' upon', ' a']
INFO:root:Predicted n-gram: ['.', ' taco', ' >=', ' liaison'], Target n-gram: ['.', ' Max', ' wanted', ' to']
INFO:root:Predicted n-gram: ['ş', ' day', ',', ' upon'], Target n-gram: [' fun', ' things', ' and', ' the']
INFO:root:Predicted n-gram: ['.', ' ItemLevel', '<|endoftext|>', '010'], Target n-gram: [' Tom', ' asked', '.', '\n']
INFO:root:Predicted n-gram: ['|', '"', 'of', ' looked'], Target n-gram: ['|', 'end', 'of', 'text']
INFO:root:Predicted n-gram: ['ş', ' day', ',', ' upon'], Target n-gram: [' group', ' and', ' they', ' played']
INFO:root:Predicted n-gram: [' small', 'minute', ' provoked', ' demol'], Target n-gram: [' friends', ' and', ' played', ' together']
INFO:root:Predicted n-gram: ['|', '"', 'of', ' m'], Target n-gram: ['".', '\n', 'But', ' it']
INFO:root:Predicted n-gram: ['.', ' ItemLevel', 'IAL', '010'], Target n-gram: ['."', ' They', ' pushed', ' and']
INFO:root:Predicted n-gram: ['.', '"', '<|endoftext|>', 'events'], Target n-gram: ['.', ' His', ' mum', ' agreed']
INFO:root:Predicted n-gram: [' friends', 'weapon', '<|endoftext|>', ' grou'], Target n-gram: [' said', ',', ' "', 'The']
INFO:root:Predicted n-gram: [' McCann', ' Announce', ',', ' Challenges'], Target n-gram: [' a', ' friend', ',', ' "']
INFO:root:Predicted n-gram: [' and', ' Sunny', ' there', 'grey'], Target n-gram: [' rang', '.', ' It', ' was']
INFO:root:Predicted n-gram: [' and', ' ItemLevel', ' there', ' liaison'], Target n-gram: [' the', ' right', ' one', '.']
INFO:root:Predicted n-gram: [' leve', ' proficiency', ',', ' Ober'], Target n-gram: ['.', ' He', ' used', ' it']
INFO:root:Step 1001, Learning Rate: 0.0001648325139778046
INFO:root:Entering gradient accumulation loop for step 1001
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0233, Head Loss: 0.1885
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0319, Head Loss: 0.1635
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0381, Head Loss: 0.1588
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0442, Head Loss: 0.1678
INFO:root:Final accum gradient norm after all heads: 0.0442, Total Loss: 21.7178, Average Loss: 5.4294
INFO:root:Step 1002, Learning Rate: 0.0001646014966195185
INFO:root:Entering gradient accumulation loop for step 1002
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0208, Head Loss: 0.1553
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0316, Head Loss: 0.1764
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0390, Head Loss: 0.1610
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0454, Head Loss: 0.1608
INFO:root:Final accum gradient norm after all heads: 0.0454, Total Loss: 20.9136, Average Loss: 5.2284
INFO:root:Step 1003, Learning Rate: 0.0001643704442904816
INFO:root:Entering gradient accumulation loop for step 1003
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0235, Head Loss: 0.1660
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0288, Head Loss: 0.1480
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0341, Head Loss: 0.1618
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0384, Head Loss: 0.1570
INFO:root:Final accum gradient norm after all heads: 0.0384, Total Loss: 20.2496, Average Loss: 5.0624
INFO:root:Step 1004, Learning Rate: 0.00016413935754406705
INFO:root:Entering gradient accumulation loop for step 1004
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0253, Head Loss: 0.1780
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0404, Head Loss: 0.2009
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0456, Head Loss: 0.1631
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0526, Head Loss: 0.1774
INFO:root:Final accum gradient norm after all heads: 0.0526, Total Loss: 23.0210, Average Loss: 5.7552
INFO:root:Step 1005, Learning Rate: 0.00016390823693373014
INFO:root:Entering gradient accumulation loop for step 1005
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0252, Head Loss: 0.1866
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0429, Head Loss: 0.1915
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0470, Head Loss: 0.1713
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0560, Head Loss: 0.1758
INFO:root:Final accum gradient norm after all heads: 0.0560, Total Loss: 23.2026, Average Loss: 5.8007
INFO:root:Step 1006, Learning Rate: 0.00016367708301300737
INFO:root:Entering gradient accumulation loop for step 1006
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0255, Head Loss: 0.1629
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0353, Head Loss: 0.1938
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0439, Head Loss: 0.1641
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0508, Head Loss: 0.1763
INFO:root:Final accum gradient norm after all heads: 0.0508, Total Loss: 22.3033, Average Loss: 5.5758
INFO:root:Step 1007, Learning Rate: 0.00016344589633551502
INFO:root:Entering gradient accumulation loop for step 1007
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0198, Head Loss: 0.1821
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0263, Head Loss: 0.1551
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0350, Head Loss: 0.1626
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0460, Head Loss: 0.1691
INFO:root:Final accum gradient norm after all heads: 0.0460, Total Loss: 21.4019, Average Loss: 5.3505
INFO:root:Step 1008, Learning Rate: 0.00016321467745494778
INFO:root:Entering gradient accumulation loop for step 1008
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0178, Head Loss: 0.1464
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0274, Head Loss: 0.1482
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0381, Head Loss: 0.1423
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0494, Head Loss: 0.1927
INFO:root:Final accum gradient norm after all heads: 0.0494, Total Loss: 20.1484, Average Loss: 5.0371
INFO:root:Step 1009, Learning Rate: 0.00016298342692507763
INFO:root:Entering gradient accumulation loop for step 1009
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0249, Head Loss: 0.1654
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0308, Head Loss: 0.1401
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0406, Head Loss: 0.1841
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0442, Head Loss: 0.1583
INFO:root:Final accum gradient norm after all heads: 0.0442, Total Loss: 20.7343, Average Loss: 5.1836
INFO:root:Step 1010, Learning Rate: 0.00016275214529975208
INFO:root:Entering gradient accumulation loop for step 1010
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0247, Head Loss: 0.1552
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0346, Head Loss: 0.1673
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0384, Head Loss: 0.1623
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0434, Head Loss: 0.1434
INFO:root:Final accum gradient norm after all heads: 0.0434, Total Loss: 20.1009, Average Loss: 5.0252
INFO:root:Step 1011, Learning Rate: 0.00016252083313289328
INFO:root:Entering gradient accumulation loop for step 1011
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0270, Head Loss: 0.1763
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0342, Head Loss: 0.1710
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0412, Head Loss: 0.1576
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0499, Head Loss: 0.1758
INFO:root:Final accum gradient norm after all heads: 0.0499, Total Loss: 21.7817, Average Loss: 5.4454
INFO:root:Step 1012, Learning Rate: 0.00016228949097849658
INFO:root:Entering gradient accumulation loop for step 1012
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0297, Head Loss: 0.1823
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0356, Head Loss: 0.1384
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0437, Head Loss: 0.1834
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0461, Head Loss: 0.1516
INFO:root:Final accum gradient norm after all heads: 0.0461, Total Loss: 20.9838, Average Loss: 5.2459
INFO:root:Step 1013, Learning Rate: 0.000162058119390629
INFO:root:Entering gradient accumulation loop for step 1013
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0279, Head Loss: 0.1756
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0372, Head Loss: 0.1845
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0433, Head Loss: 0.1613
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0499, Head Loss: 0.1808
INFO:root:Final accum gradient norm after all heads: 0.0499, Total Loss: 22.4703, Average Loss: 5.6176
INFO:root:Step 1014, Learning Rate: 0.00016182671892342817
INFO:root:Entering gradient accumulation loop for step 1014
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0314, Head Loss: 0.1842
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0360, Head Loss: 0.1484
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0443, Head Loss: 0.1553
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0480, Head Loss: 0.1498
INFO:root:Final accum gradient norm after all heads: 0.0480, Total Loss: 20.4054, Average Loss: 5.1013
INFO:root:Step 1015, Learning Rate: 0.0001615952901311008
INFO:root:Entering gradient accumulation loop for step 1015
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0231, Head Loss: 0.1589
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0309, Head Loss: 0.1899
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0378, Head Loss: 0.1650
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0466, Head Loss: 0.1946
INFO:root:Final accum gradient norm after all heads: 0.0466, Total Loss: 22.6670, Average Loss: 5.6667
INFO:root:Step 1016, Learning Rate: 0.00016136383356792156
INFO:root:Entering gradient accumulation loop for step 1016
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0184, Head Loss: 0.1581
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0321, Head Loss: 0.2092
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0372, Head Loss: 0.1755
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0454, Head Loss: 0.1876
INFO:root:Final accum gradient norm after all heads: 0.0454, Total Loss: 23.3734, Average Loss: 5.8434
INFO:root:Step 1017, Learning Rate: 0.00016113234978823145
INFO:root:Entering gradient accumulation loop for step 1017
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0235, Head Loss: 0.1715
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0407, Head Loss: 0.1858
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0443, Head Loss: 0.1565
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0484, Head Loss: 0.1673
INFO:root:Final accum gradient norm after all heads: 0.0484, Total Loss: 21.7950, Average Loss: 5.4487
INFO:root:Step 1018, Learning Rate: 0.00016090083934643684
INFO:root:Entering gradient accumulation loop for step 1018
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0198, Head Loss: 0.1714
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0291, Head Loss: 0.1352
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0389, Head Loss: 0.1691
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0424, Head Loss: 0.1539
INFO:root:Final accum gradient norm after all heads: 0.0424, Total Loss: 20.1472, Average Loss: 5.0368
INFO:root:Step 1019, Learning Rate: 0.00016066930279700787
INFO:root:Entering gradient accumulation loop for step 1019
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0200, Head Loss: 0.1567
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0291, Head Loss: 0.1560
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0382, Head Loss: 0.1443
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0417, Head Loss: 0.1388
INFO:root:Final accum gradient norm after all heads: 0.0417, Total Loss: 19.0665, Average Loss: 4.7666
INFO:root:Step 1020, Learning Rate: 0.00016043774069447717
INFO:root:Entering gradient accumulation loop for step 1020
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0239, Head Loss: 0.1725
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0317, Head Loss: 0.1689
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0380, Head Loss: 0.1656
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0467, Head Loss: 0.1850
INFO:root:Final accum gradient norm after all heads: 0.0467, Total Loss: 22.1465, Average Loss: 5.5366
INFO:root:Step 1021, Learning Rate: 0.00016020615359343864
INFO:root:Entering gradient accumulation loop for step 1021
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0156, Head Loss: 0.1427
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0334, Head Loss: 0.1570
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0475, Head Loss: 0.2020
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0502, Head Loss: 0.1504
INFO:root:Final accum gradient norm after all heads: 0.0502, Total Loss: 20.8696, Average Loss: 5.2174
INFO:root:Step 1022, Learning Rate: 0.00015997454204854603
INFO:root:Entering gradient accumulation loop for step 1022
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0266, Head Loss: 0.1777
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0403, Head Loss: 0.1730
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0483, Head Loss: 0.1793
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0540, Head Loss: 0.1704
INFO:root:Final accum gradient norm after all heads: 0.0540, Total Loss: 22.4149, Average Loss: 5.6037
INFO:root:Step 1023, Learning Rate: 0.0001597429066145116
INFO:root:Entering gradient accumulation loop for step 1023
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0191, Head Loss: 0.1624
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0397, Head Loss: 0.2061
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0473, Head Loss: 0.1517
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0533, Head Loss: 0.1630
INFO:root:Final accum gradient norm after all heads: 0.0533, Total Loss: 21.8607, Average Loss: 5.4652
INFO:root:Step 1024, Learning Rate: 0.00015951124784610492
INFO:root:Entering gradient accumulation loop for step 1024
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0232, Head Loss: 0.1798
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0279, Head Loss: 0.1726
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0357, Head Loss: 0.1711
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0434, Head Loss: 0.1728
INFO:root:Final accum gradient norm after all heads: 0.0434, Total Loss: 22.2802, Average Loss: 5.5701
INFO:root:Step 1025, Learning Rate: 0.00015927956629815127
INFO:root:Entering gradient accumulation loop for step 1025
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0239, Head Loss: 0.1812
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0327, Head Loss: 0.1745
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0421, Head Loss: 0.1763
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0540, Head Loss: 0.1987
INFO:root:Final accum gradient norm after all heads: 0.0540, Total Loss: 23.3843, Average Loss: 5.8461
INFO:root:Step 1026, Learning Rate: 0.00015904786252553068
INFO:root:Entering gradient accumulation loop for step 1026
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0230, Head Loss: 0.1569
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0281, Head Loss: 0.1346
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0334, Head Loss: 0.1322
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0401, Head Loss: 0.1581
INFO:root:Final accum gradient norm after all heads: 0.0401, Total Loss: 18.6199, Average Loss: 4.6550
INFO:root:Step 1027, Learning Rate: 0.0001588161370831763
INFO:root:Entering gradient accumulation loop for step 1027
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0235, Head Loss: 0.1854
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0373, Head Loss: 0.1563
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0458, Head Loss: 0.1825
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0506, Head Loss: 0.1707
INFO:root:Final accum gradient norm after all heads: 0.0506, Total Loss: 22.2338, Average Loss: 5.5584
INFO:root:Step 1028, Learning Rate: 0.00015858439052607317
INFO:root:Entering gradient accumulation loop for step 1028
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0234, Head Loss: 0.1342
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0303, Head Loss: 0.1628
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0343, Head Loss: 0.1594
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0381, Head Loss: 0.1292
INFO:root:Final accum gradient norm after all heads: 0.0381, Total Loss: 18.7397, Average Loss: 4.6849
INFO:root:Step 1029, Learning Rate: 0.00015835262340925703
INFO:root:Entering gradient accumulation loop for step 1029
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0221, Head Loss: 0.1638
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0362, Head Loss: 0.1761
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0464, Head Loss: 0.1655
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0528, Head Loss: 0.1795
INFO:root:Final accum gradient norm after all heads: 0.0528, Total Loss: 21.9154, Average Loss: 5.4789
INFO:root:Step 1030, Learning Rate: 0.0001581208362878126
INFO:root:Entering gradient accumulation loop for step 1030
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0285, Head Loss: 0.1874
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0393, Head Loss: 0.1556
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0440, Head Loss: 0.1513
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0493, Head Loss: 0.1620
INFO:root:Final accum gradient norm after all heads: 0.0493, Total Loss: 21.0012, Average Loss: 5.2503
INFO:root:Step 1031, Learning Rate: 0.00015788902971687285
INFO:root:Entering gradient accumulation loop for step 1031
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0219, Head Loss: 0.1788
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0369, Head Loss: 0.1872
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0412, Head Loss: 0.1245
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0506, Head Loss: 0.2002
INFO:root:Final accum gradient norm after all heads: 0.0506, Total Loss: 22.1020, Average Loss: 5.5255
INFO:root:Step 1032, Learning Rate: 0.00015765720425161707
INFO:root:Entering gradient accumulation loop for step 1032
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0305, Head Loss: 0.1818
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0408, Head Loss: 0.1852
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0490, Head Loss: 0.1578
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0529, Head Loss: 0.1441
INFO:root:Final accum gradient norm after all heads: 0.0529, Total Loss: 21.4033, Average Loss: 5.3508
INFO:root:Step 1033, Learning Rate: 0.0001574253604472699
INFO:root:Entering gradient accumulation loop for step 1033
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0281, Head Loss: 0.1734
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0340, Head Loss: 0.1854
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0386, Head Loss: 0.1482
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0461, Head Loss: 0.1935
INFO:root:Final accum gradient norm after all heads: 0.0461, Total Loss: 22.4175, Average Loss: 5.6044
INFO:root:Step 1034, Learning Rate: 0.00015719349885909991
INFO:root:Entering gradient accumulation loop for step 1034
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0238, Head Loss: 0.1576
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0353, Head Loss: 0.1649
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0402, Head Loss: 0.1623
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0471, Head Loss: 0.1297
INFO:root:Final accum gradient norm after all heads: 0.0471, Total Loss: 19.6655, Average Loss: 4.9164
INFO:root:Step 1035, Learning Rate: 0.0001569616200424182
INFO:root:Entering gradient accumulation loop for step 1035
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0234, Head Loss: 0.1638
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0299, Head Loss: 0.1579
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0420, Head Loss: 0.2031
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0496, Head Loss: 0.1865
INFO:root:Final accum gradient norm after all heads: 0.0496, Total Loss: 22.7645, Average Loss: 5.6911
INFO:root:Step 1036, Learning Rate: 0.00015672972455257723
INFO:root:Entering gradient accumulation loop for step 1036
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0203, Head Loss: 0.1476
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0282, Head Loss: 0.1704
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0354, Head Loss: 0.1724
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0427, Head Loss: 0.1749
INFO:root:Final accum gradient norm after all heads: 0.0427, Total Loss: 21.2897, Average Loss: 5.3224
INFO:root:Step 1037, Learning Rate: 0.00015649781294496933
INFO:root:Entering gradient accumulation loop for step 1037
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0261, Head Loss: 0.1872
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0351, Head Loss: 0.1786
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0418, Head Loss: 0.1660
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0471, Head Loss: 0.1664
INFO:root:Final accum gradient norm after all heads: 0.0471, Total Loss: 22.3388, Average Loss: 5.5847
INFO:root:Step 1038, Learning Rate: 0.0001562658857750254
INFO:root:Entering gradient accumulation loop for step 1038
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0227, Head Loss: 0.1470
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0328, Head Loss: 0.1856
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0419, Head Loss: 0.1575
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0522, Head Loss: 0.1813
INFO:root:Final accum gradient norm after all heads: 0.0522, Total Loss: 21.4860, Average Loss: 5.3715
INFO:root:Step 1039, Learning Rate: 0.00015603394359821367
INFO:root:Entering gradient accumulation loop for step 1039
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0193, Head Loss: 0.1675
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0318, Head Loss: 0.1725
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0420, Head Loss: 0.1759
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0485, Head Loss: 0.1620
INFO:root:Final accum gradient norm after all heads: 0.0485, Total Loss: 21.6891, Average Loss: 5.4223
INFO:root:Step 1040, Learning Rate: 0.0001558019869700383
INFO:root:Entering gradient accumulation loop for step 1040
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0284, Head Loss: 0.1794
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0371, Head Loss: 0.1983
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0421, Head Loss: 0.1770
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0515, Head Loss: 0.1670
INFO:root:Final accum gradient norm after all heads: 0.0515, Total Loss: 23.0905, Average Loss: 5.7726
INFO:root:Step 1041, Learning Rate: 0.0001555700164460381
INFO:root:Entering gradient accumulation loop for step 1041
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0214, Head Loss: 0.1628
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0295, Head Loss: 0.1575
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0383, Head Loss: 0.1638
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0441, Head Loss: 0.1698
INFO:root:Final accum gradient norm after all heads: 0.0441, Total Loss: 20.9276, Average Loss: 5.2319
INFO:root:Step 1042, Learning Rate: 0.00015533803258178502
INFO:root:Entering gradient accumulation loop for step 1042
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0208, Head Loss: 0.1835
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0305, Head Loss: 0.1628
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0425, Head Loss: 0.1846
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0477, Head Loss: 0.1753
INFO:root:Final accum gradient norm after all heads: 0.0477, Total Loss: 22.6005, Average Loss: 5.6501
INFO:root:Step 1043, Learning Rate: 0.00015510603593288318
INFO:root:Entering gradient accumulation loop for step 1043
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0216, Head Loss: 0.1543
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0289, Head Loss: 0.1654
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0337, Head Loss: 0.1465
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0425, Head Loss: 0.1914
INFO:root:Final accum gradient norm after all heads: 0.0425, Total Loss: 21.0455, Average Loss: 5.2614
INFO:root:Step 1044, Learning Rate: 0.00015487402705496707
INFO:root:Entering gradient accumulation loop for step 1044
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0212, Head Loss: 0.1600
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0280, Head Loss: 0.1592
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0411, Head Loss: 0.1840
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0502, Head Loss: 0.1706
INFO:root:Final accum gradient norm after all heads: 0.0502, Total Loss: 21.5594, Average Loss: 5.3898
INFO:root:Step 1045, Learning Rate: 0.00015464200650370066
INFO:root:Entering gradient accumulation loop for step 1045
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0253, Head Loss: 0.1731
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0387, Head Loss: 0.2060
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0507, Head Loss: 0.1735
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0545, Head Loss: 0.1805
INFO:root:Final accum gradient norm after all heads: 0.0545, Total Loss: 23.4608, Average Loss: 5.8652
INFO:root:Step 1046, Learning Rate: 0.00015440997483477583
INFO:root:Entering gradient accumulation loop for step 1046
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0261, Head Loss: 0.1598
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0365, Head Loss: 0.1933
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0433, Head Loss: 0.1630
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0515, Head Loss: 0.1805
INFO:root:Final accum gradient norm after all heads: 0.0515, Total Loss: 22.2917, Average Loss: 5.5729
INFO:root:Step 1047, Learning Rate: 0.00015417793260391103
INFO:root:Entering gradient accumulation loop for step 1047
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0216, Head Loss: 0.1423
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0338, Head Loss: 0.1695
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0428, Head Loss: 0.1915
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0482, Head Loss: 0.1491
INFO:root:Final accum gradient norm after all heads: 0.0482, Total Loss: 20.8801, Average Loss: 5.2200
INFO:root:Step 1048, Learning Rate: 0.00015394588036685012
INFO:root:Entering gradient accumulation loop for step 1048
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0186, Head Loss: 0.1394
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0338, Head Loss: 0.1834
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0407, Head Loss: 0.1713
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0475, Head Loss: 0.1723
INFO:root:Final accum gradient norm after all heads: 0.0475, Total Loss: 21.3248, Average Loss: 5.3312
INFO:root:Step 1049, Learning Rate: 0.00015371381867936078
INFO:root:Entering gradient accumulation loop for step 1049
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0319, Head Loss: 0.1829
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0436, Head Loss: 0.1756
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0495, Head Loss: 0.1645
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0563, Head Loss: 0.1711
INFO:root:Final accum gradient norm after all heads: 0.0563, Total Loss: 22.2128, Average Loss: 5.5532
INFO:root:Step 1050, Learning Rate: 0.00015348174809723335
INFO:root:Entering gradient accumulation loop for step 1050
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0235, Head Loss: 0.1775
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0320, Head Loss: 0.1742
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0407, Head Loss: 0.1706
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0476, Head Loss: 0.1643
INFO:root:Final accum gradient norm after all heads: 0.0476, Total Loss: 21.9690, Average Loss: 5.4922
INFO:root:Step 1050: Loss 5.49, Norm: 2.1820, Time: 22.99s, Tokens Seen: 265.0M
INFO:root:Step 1051, Learning Rate: 0.0001532496691762796
INFO:root:Entering gradient accumulation loop for step 1051
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0373, Head Loss: 0.1991
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0448, Head Loss: 0.1770
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0528, Head Loss: 0.1869
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0578, Head Loss: 0.1819
INFO:root:Final accum gradient norm after all heads: 0.0578, Total Loss: 23.8369, Average Loss: 5.9592
INFO:root:Step 1052, Learning Rate: 0.00015301758247233117
INFO:root:Entering gradient accumulation loop for step 1052
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0295, Head Loss: 0.2002
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0401, Head Loss: 0.1463
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0500, Head Loss: 0.1818
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0620, Head Loss: 0.2054
INFO:root:Final accum gradient norm after all heads: 0.0620, Total Loss: 23.4796, Average Loss: 5.8699
INFO:root:Step 1053, Learning Rate: 0.00015278548854123834
INFO:root:Entering gradient accumulation loop for step 1053
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0258, Head Loss: 0.1947
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0385, Head Loss: 0.1743
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0477, Head Loss: 0.1819
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0522, Head Loss: 0.1559
INFO:root:Final accum gradient norm after all heads: 0.0522, Total Loss: 22.6182, Average Loss: 5.6545
INFO:root:Step 1054, Learning Rate: 0.00015255338793886876
INFO:root:Entering gradient accumulation loop for step 1054
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0143, Head Loss: 0.1389
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0281, Head Loss: 0.1518
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0348, Head Loss: 0.1680
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0426, Head Loss: 0.1638
INFO:root:Final accum gradient norm after all heads: 0.0426, Total Loss: 19.9220, Average Loss: 4.9805
INFO:root:Step 1055, Learning Rate: 0.00015232128122110597
INFO:root:Entering gradient accumulation loop for step 1055
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0230, Head Loss: 0.1670
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0301, Head Loss: 0.1842
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0354, Head Loss: 0.1523
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0448, Head Loss: 0.1885
INFO:root:Final accum gradient norm after all heads: 0.0448, Total Loss: 22.1440, Average Loss: 5.5360
INFO:root:Step 1056, Learning Rate: 0.00015208916894384822
INFO:root:Entering gradient accumulation loop for step 1056
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0291, Head Loss: 0.1728
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0356, Head Loss: 0.1689
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0430, Head Loss: 0.1784
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0507, Head Loss: 0.1965
INFO:root:Final accum gradient norm after all heads: 0.0507, Total Loss: 22.9301, Average Loss: 5.7325
INFO:root:Step 1057, Learning Rate: 0.00015185705166300702
INFO:root:Entering gradient accumulation loop for step 1057
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0264, Head Loss: 0.1764
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0359, Head Loss: 0.1658
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0407, Head Loss: 0.1695
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0476, Head Loss: 0.1749
INFO:root:Final accum gradient norm after all heads: 0.0476, Total Loss: 21.9727, Average Loss: 5.4932
INFO:root:Step 1058, Learning Rate: 0.00015162492993450597
INFO:root:Entering gradient accumulation loop for step 1058
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0162, Head Loss: 0.1848
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0237, Head Loss: 0.1539
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0320, Head Loss: 0.1677
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0396, Head Loss: 0.1769
INFO:root:Final accum gradient norm after all heads: 0.0396, Total Loss: 21.8629, Average Loss: 5.4657
INFO:root:Step 1059, Learning Rate: 0.00015139280431427927
INFO:root:Entering gradient accumulation loop for step 1059
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0236, Head Loss: 0.1694
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0327, Head Loss: 0.1579
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0430, Head Loss: 0.1551
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0522, Head Loss: 0.1777
INFO:root:Final accum gradient norm after all heads: 0.0522, Total Loss: 21.1241, Average Loss: 5.2810
INFO:root:Step 1060, Learning Rate: 0.0001511606753582703
INFO:root:Entering gradient accumulation loop for step 1060
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0175, Head Loss: 0.1528
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0368, Head Loss: 0.1850
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0419, Head Loss: 0.1567
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0465, Head Loss: 0.1704
INFO:root:Final accum gradient norm after all heads: 0.0465, Total Loss: 21.2766, Average Loss: 5.3192
INFO:root:Step 1061, Learning Rate: 0.00015092854362243067
INFO:root:Entering gradient accumulation loop for step 1061
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0223, Head Loss: 0.1654
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0310, Head Loss: 0.1699
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0373, Head Loss: 0.1471
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0466, Head Loss: 0.1764
INFO:root:Final accum gradient norm after all heads: 0.0466, Total Loss: 21.0780, Average Loss: 5.2695
INFO:root:Step 1062, Learning Rate: 0.00015069640966271846
INFO:root:Entering gradient accumulation loop for step 1062
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0289, Head Loss: 0.1837
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0337, Head Loss: 0.1488
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0417, Head Loss: 0.1728
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0470, Head Loss: 0.1569
INFO:root:Final accum gradient norm after all heads: 0.0470, Total Loss: 21.1877, Average Loss: 5.2969
INFO:root:Step 1063, Learning Rate: 0.00015046427403509721
INFO:root:Entering gradient accumulation loop for step 1063
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0227, Head Loss: 0.1819
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0324, Head Loss: 0.1596
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0407, Head Loss: 0.1702
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0442, Head Loss: 0.1492
INFO:root:Final accum gradient norm after all heads: 0.0442, Total Loss: 21.1500, Average Loss: 5.2875
INFO:root:Step 1064, Learning Rate: 0.00015023213729553432
INFO:root:Entering gradient accumulation loop for step 1064
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0173, Head Loss: 0.1513
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0302, Head Loss: 0.1717
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0371, Head Loss: 0.1476
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0425, Head Loss: 0.1662
INFO:root:Final accum gradient norm after all heads: 0.0425, Total Loss: 20.3778, Average Loss: 5.0945
INFO:root:Step 1065, Learning Rate: 0.00015
INFO:root:Entering gradient accumulation loop for step 1065
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0266, Head Loss: 0.1689
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0330, Head Loss: 0.1587
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0421, Head Loss: 0.1602
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0462, Head Loss: 0.1559
INFO:root:Final accum gradient norm after all heads: 0.0462, Total Loss: 20.6028, Average Loss: 5.1507
INFO:root:Step 1066, Learning Rate: 0.00014976786270446565
INFO:root:Entering gradient accumulation loop for step 1066
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0222, Head Loss: 0.1832
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0311, Head Loss: 0.1812
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0366, Head Loss: 0.1627
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0415, Head Loss: 0.1820
INFO:root:Final accum gradient norm after all heads: 0.0415, Total Loss: 22.6893, Average Loss: 5.6723
INFO:root:Step 1067, Learning Rate: 0.00014953572596490284
INFO:root:Entering gradient accumulation loop for step 1067
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0294, Head Loss: 0.1927
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0358, Head Loss: 0.1548
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0451, Head Loss: 0.1763
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0500, Head Loss: 0.1589
INFO:root:Final accum gradient norm after all heads: 0.0500, Total Loss: 21.8449, Average Loss: 5.4612
INFO:root:Step 1068, Learning Rate: 0.00014930359033728154
INFO:root:Entering gradient accumulation loop for step 1068
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0251, Head Loss: 0.1620
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0344, Head Loss: 0.1799
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0442, Head Loss: 0.1701
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0486, Head Loss: 0.1683
INFO:root:Final accum gradient norm after all heads: 0.0486, Total Loss: 21.7712, Average Loss: 5.4428
INFO:root:Step 1069, Learning Rate: 0.00014907145637756933
INFO:root:Entering gradient accumulation loop for step 1069
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0223, Head Loss: 0.1504
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0352, Head Loss: 0.1679
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0389, Head Loss: 0.1487
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0422, Head Loss: 0.1405
INFO:root:Final accum gradient norm after all heads: 0.0422, Total Loss: 19.4387, Average Loss: 4.8597
INFO:root:Step 1070, Learning Rate: 0.00014883932464172968
INFO:root:Entering gradient accumulation loop for step 1070
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0219, Head Loss: 0.1742
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0391, Head Loss: 0.1900
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0440, Head Loss: 0.1571
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0487, Head Loss: 0.1692
INFO:root:Final accum gradient norm after all heads: 0.0487, Total Loss: 22.0944, Average Loss: 5.5236
INFO:root:Step 1071, Learning Rate: 0.00014860719568572076
INFO:root:Entering gradient accumulation loop for step 1071
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0225, Head Loss: 0.1501
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0299, Head Loss: 0.1631
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0353, Head Loss: 0.1537
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0442, Head Loss: 0.1771
INFO:root:Final accum gradient norm after all heads: 0.0442, Total Loss: 20.6117, Average Loss: 5.1529
INFO:root:Step 1072, Learning Rate: 0.00014837507006549403
INFO:root:Entering gradient accumulation loop for step 1072
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0167, Head Loss: 0.1758
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0257, Head Loss: 0.1589
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0334, Head Loss: 0.1336
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0372, Head Loss: 0.1267
INFO:root:Final accum gradient norm after all heads: 0.0372, Total Loss: 19.0433, Average Loss: 4.7608
INFO:root:Step 1073, Learning Rate: 0.00014814294833699295
INFO:root:Entering gradient accumulation loop for step 1073
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0200, Head Loss: 0.1638
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0329, Head Loss: 0.1748
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0448, Head Loss: 0.1835
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0513, Head Loss: 0.1888
INFO:root:Final accum gradient norm after all heads: 0.0513, Total Loss: 22.7482, Average Loss: 5.6871
INFO:root:Step 1074, Learning Rate: 0.0001479108310561518
INFO:root:Entering gradient accumulation loop for step 1074
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0198, Head Loss: 0.1416
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0268, Head Loss: 0.1422
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0349, Head Loss: 0.1712
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0410, Head Loss: 0.1718
INFO:root:Final accum gradient norm after all heads: 0.0410, Total Loss: 20.0566, Average Loss: 5.0141
INFO:root:Step 1075, Learning Rate: 0.00014767871877889403
INFO:root:Entering gradient accumulation loop for step 1075
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0204, Head Loss: 0.1648
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0296, Head Loss: 0.1572
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0403, Head Loss: 0.1783
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0455, Head Loss: 0.1656
INFO:root:Final accum gradient norm after all heads: 0.0455, Total Loss: 21.3105, Average Loss: 5.3276
INFO:root:Step 1076, Learning Rate: 0.0001474466120611312
INFO:root:Entering gradient accumulation loop for step 1076
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0296, Head Loss: 0.1472
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0388, Head Loss: 0.1656
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0438, Head Loss: 0.1781
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0495, Head Loss: 0.1490
INFO:root:Final accum gradient norm after all heads: 0.0495, Total Loss: 20.4771, Average Loss: 5.1193
INFO:root:Step 1077, Learning Rate: 0.00014721451145876169
INFO:root:Entering gradient accumulation loop for step 1077
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0238, Head Loss: 0.1691
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0305, Head Loss: 0.1595
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0403, Head Loss: 0.1809
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0479, Head Loss: 0.1659
INFO:root:Final accum gradient norm after all heads: 0.0479, Total Loss: 21.6124, Average Loss: 5.4031
INFO:root:Step 1078, Learning Rate: 0.00014698241752766883
INFO:root:Entering gradient accumulation loop for step 1078
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0275, Head Loss: 0.1795
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0408, Head Loss: 0.1655
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0484, Head Loss: 0.1754
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0563, Head Loss: 0.1839
INFO:root:Final accum gradient norm after all heads: 0.0563, Total Loss: 22.5377, Average Loss: 5.6344
INFO:root:Step 1079, Learning Rate: 0.00014675033082372038
INFO:root:Entering gradient accumulation loop for step 1079
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0207, Head Loss: 0.1638
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0300, Head Loss: 0.1548
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0412, Head Loss: 0.1788
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0458, Head Loss: 0.1744
INFO:root:Final accum gradient norm after all heads: 0.0458, Total Loss: 21.4961, Average Loss: 5.3740
INFO:root:Step 1080, Learning Rate: 0.00014651825190276663
INFO:root:Entering gradient accumulation loop for step 1080
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0259, Head Loss: 0.1629
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0331, Head Loss: 0.1619
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0415, Head Loss: 0.1700
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0442, Head Loss: 0.1586
INFO:root:Final accum gradient norm after all heads: 0.0442, Total Loss: 20.9056, Average Loss: 5.2264
INFO:root:Step 1081, Learning Rate: 0.00014628618132063928
INFO:root:Entering gradient accumulation loop for step 1081
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0221, Head Loss: 0.1326
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0313, Head Loss: 0.1744
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0382, Head Loss: 0.1770
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0428, Head Loss: 0.1708
INFO:root:Final accum gradient norm after all heads: 0.0428, Total Loss: 20.9520, Average Loss: 5.2380
INFO:root:Step 1082, Learning Rate: 0.00014605411963314988
INFO:root:Entering gradient accumulation loop for step 1082
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0242, Head Loss: 0.1753
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0323, Head Loss: 0.1794
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0411, Head Loss: 0.1685
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0479, Head Loss: 0.1810
INFO:root:Final accum gradient norm after all heads: 0.0479, Total Loss: 22.5341, Average Loss: 5.6335
INFO:root:Step 1083, Learning Rate: 0.00014582206739608891
INFO:root:Entering gradient accumulation loop for step 1083
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0278, Head Loss: 0.1795
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0378, Head Loss: 0.1627
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0438, Head Loss: 0.1579
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0475, Head Loss: 0.1316
INFO:root:Final accum gradient norm after all heads: 0.0475, Total Loss: 20.2180, Average Loss: 5.0545
INFO:root:Step 1084, Learning Rate: 0.00014559002516522415
INFO:root:Entering gradient accumulation loop for step 1084
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0211, Head Loss: 0.1604
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0344, Head Loss: 0.1851
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0413, Head Loss: 0.1654
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0471, Head Loss: 0.1857
INFO:root:Final accum gradient norm after all heads: 0.0471, Total Loss: 22.2925, Average Loss: 5.5731
INFO:root:Step 1085, Learning Rate: 0.00014535799349629935
INFO:root:Entering gradient accumulation loop for step 1085
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0175, Head Loss: 0.1686
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0283, Head Loss: 0.1705
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0372, Head Loss: 0.1499
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0461, Head Loss: 0.1641
INFO:root:Final accum gradient norm after all heads: 0.0461, Total Loss: 20.8972, Average Loss: 5.2243
INFO:root:Step 1086, Learning Rate: 0.00014512597294503293
INFO:root:Entering gradient accumulation loop for step 1086
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0262, Head Loss: 0.1794
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0354, Head Loss: 0.1540
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0400, Head Loss: 0.1649
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0461, Head Loss: 0.1659
INFO:root:Final accum gradient norm after all heads: 0.0461, Total Loss: 21.2571, Average Loss: 5.3143
INFO:root:Step 1087, Learning Rate: 0.00014489396406711682
INFO:root:Entering gradient accumulation loop for step 1087
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0185, Head Loss: 0.1819
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0320, Head Loss: 0.1851
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0403, Head Loss: 0.1629
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0450, Head Loss: 0.1751
INFO:root:Final accum gradient norm after all heads: 0.0450, Total Loss: 22.5574, Average Loss: 5.6394
INFO:root:Step 1088, Learning Rate: 0.00014466196741821496
INFO:root:Entering gradient accumulation loop for step 1088
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0209, Head Loss: 0.1697
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0365, Head Loss: 0.1852
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0386, Head Loss: 0.1337
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0449, Head Loss: 0.1678
INFO:root:Final accum gradient norm after all heads: 0.0449, Total Loss: 21.0052, Average Loss: 5.2513
INFO:root:Step 1089, Learning Rate: 0.0001444299835539619
INFO:root:Entering gradient accumulation loop for step 1089
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0197, Head Loss: 0.1428
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0249, Head Loss: 0.1526
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0323, Head Loss: 0.1522
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0346, Head Loss: 0.1645
INFO:root:Final accum gradient norm after all heads: 0.0346, Total Loss: 19.5862, Average Loss: 4.8966
INFO:root:Step 1090, Learning Rate: 0.00014419801302996166
INFO:root:Entering gradient accumulation loop for step 1090
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0180, Head Loss: 0.1356
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0229, Head Loss: 0.1496
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0270, Head Loss: 0.1318
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0333, Head Loss: 0.1703
INFO:root:Final accum gradient norm after all heads: 0.0333, Total Loss: 18.7945, Average Loss: 4.6986
INFO:root:Step 1091, Learning Rate: 0.00014396605640178636
INFO:root:Entering gradient accumulation loop for step 1091
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0244, Head Loss: 0.1635
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0300, Head Loss: 0.1454
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0327, Head Loss: 0.1165
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0379, Head Loss: 0.1315
INFO:root:Final accum gradient norm after all heads: 0.0379, Total Loss: 17.8182, Average Loss: 4.4545
INFO:root:Step 1092, Learning Rate: 0.00014373411422497463
INFO:root:Entering gradient accumulation loop for step 1092
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0233, Head Loss: 0.1331
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0276, Head Loss: 0.1430
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0403, Head Loss: 0.1761
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0431, Head Loss: 0.1335
INFO:root:Final accum gradient norm after all heads: 0.0431, Total Loss: 18.7391, Average Loss: 4.6848
INFO:root:Step 1093, Learning Rate: 0.00014350218705503067
INFO:root:Entering gradient accumulation loop for step 1093
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0191, Head Loss: 0.1638
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0253, Head Loss: 0.1426
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0354, Head Loss: 0.1668
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0427, Head Loss: 0.1701
INFO:root:Final accum gradient norm after all heads: 0.0427, Total Loss: 20.5840, Average Loss: 5.1460
INFO:root:Step 1094, Learning Rate: 0.0001432702754474228
INFO:root:Entering gradient accumulation loop for step 1094
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0155, Head Loss: 0.1364
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0266, Head Loss: 0.1565
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0342, Head Loss: 0.1612
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0405, Head Loss: 0.1681
INFO:root:Final accum gradient norm after all heads: 0.0405, Total Loss: 19.9104, Average Loss: 4.9776
INFO:root:Step 1095, Learning Rate: 0.0001430383799575818
INFO:root:Entering gradient accumulation loop for step 1095
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0199, Head Loss: 0.1618
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0342, Head Loss: 0.1763
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0407, Head Loss: 0.1685
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0464, Head Loss: 0.1612
INFO:root:Final accum gradient norm after all heads: 0.0464, Total Loss: 21.3678, Average Loss: 5.3420
INFO:root:Step 1096, Learning Rate: 0.0001428065011409001
INFO:root:Entering gradient accumulation loop for step 1096
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0280, Head Loss: 0.1794
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0391, Head Loss: 0.1724
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0456, Head Loss: 0.1740
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0496, Head Loss: 0.1443
INFO:root:Final accum gradient norm after all heads: 0.0496, Total Loss: 21.4424, Average Loss: 5.3606
INFO:root:Step 1097, Learning Rate: 0.00014257463955273005
INFO:root:Entering gradient accumulation loop for step 1097
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0134, Head Loss: 0.1579
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0221, Head Loss: 0.1536
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0344, Head Loss: 0.1618
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0406, Head Loss: 0.1663
INFO:root:Final accum gradient norm after all heads: 0.0406, Total Loss: 20.4671, Average Loss: 5.1168
INFO:root:Step 1098, Learning Rate: 0.00014234279574838296
INFO:root:Entering gradient accumulation loop for step 1098
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0176, Head Loss: 0.1717
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0309, Head Loss: 0.1476
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0354, Head Loss: 0.1693
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0396, Head Loss: 0.1661
INFO:root:Final accum gradient norm after all heads: 0.0396, Total Loss: 20.9514, Average Loss: 5.2379
INFO:root:Step 1099, Learning Rate: 0.00014211097028312715
INFO:root:Entering gradient accumulation loop for step 1099
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0190, Head Loss: 0.1597
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0298, Head Loss: 0.1534
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0388, Head Loss: 0.1599
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0456, Head Loss: 0.1529
INFO:root:Final accum gradient norm after all heads: 0.0456, Total Loss: 20.0248, Average Loss: 5.0062
INFO:root:Step 1100, Learning Rate: 0.00014187916371218736
INFO:root:Eval Step 1100 across 50 batches (0.8M Tokens): Train Loss 10.7261, Val Loss 10.7251
INFO:root:Entering gradient accumulation loop for step 1100
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0202, Head Loss: 0.1725
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0288, Head Loss: 0.1697
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0329, Head Loss: 0.1727
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0420, Head Loss: 0.1690
INFO:root:Final accum gradient norm after all heads: 0.0420, Total Loss: 21.8859, Average Loss: 5.4715
INFO:root:Step 1100: Loss 5.47, Norm: 2.2169, Time: 38.48s, Tokens Seen: 278.1M
INFO:root:Predicted n-gram: [' small', ' amount', ' Bieber', 'Atlantic'], Target n-gram: ['<|endoftext|>', 'Once', ' upon', ' a']
INFO:root:Predicted n-gram: [' and', 'este', ' upon', ' organized'], Target n-gram: [' and', ' all', ' the', ' friends']
INFO:root:Predicted n-gram: [' and', 'weapon', ' there', ' grou'], Target n-gram: ['.', ' Tim', ' was', ' right']
INFO:root:Predicted n-gram: [' Lily', 'tains', ' Bieber', ' Tal'], Target n-gram: [' car', ' thought', ',', ' "']
INFO:root:Predicted n-gram: [' and', ' you', ' there', ' water'], Target n-gram: ['ily', ' and', ' Ben', ' felt']
INFO:root:Predicted n-gram: ['.', 'tains', ' LIFE', ' liaison'], Target n-gram: [' having', ' a', ' great', ' day']
INFO:root:Predicted n-gram: [' small', ' amount', ' Bieber', 'save'], Target n-gram: [',', ' but', ' she', ' kept']
INFO:root:Predicted n-gram: [' down', '225', ' there', '"'], Target n-gram: [' He', ' tried', ' again', ' and']
INFO:root:Predicted n-gram: ['.', 'tains', 'ael', ' taco'], Target n-gram: ['\n', 'The', ' cats', ' thanked']
INFO:root:Predicted n-gram: ['ş', ' day', ',', ' upon'], Target n-gram: [' thought', ' about', ' it', ' and']
INFO:root:Predicted n-gram: ['.', 'One', ' Tanks', 'haust'], Target n-gram: ['One', ' day', ',', ' a']
INFO:root:Predicted n-gram: [' and', ' went', '<|endoftext|>', 'Once'], Target n-gram: [' wanted', ' to', ' learn', ' how']
INFO:root:Predicted n-gram: [' yellow', ' ItemLevel', ' provoked', 'Atlantic'], Target n-gram: ['>', '<|endoftext|>', 'One', ' day']
INFO:root:Predicted n-gram: ['>', 'end', ' me', ' rush'], Target n-gram: [' friend', ',', ' Sam', ',']
INFO:root:Predicted n-gram: ['.', ' went', '.', 'Once'], Target n-gram: [' the', ' frog', ' was', ' always']
INFO:root:Predicted n-gram: [' leve', ' proficiency', ',', ' Ober'], Target n-gram: [' to', ' a', ' fun', ' place']
INFO:root:Predicted n-gram: ['.', ' looked', ' Tanks', 'Once'], Target n-gram: ['.', '\n', '"', 'Look']
INFO:root:Predicted n-gram: ['.', ' lined', ' Force', ' liaison'], Target n-gram: [' The', ' little', ' bird', ' was']
INFO:root:Predicted n-gram: ['.', ' taco', ' Bieber', ' liaison'], Target n-gram: [' sun', ' comes', ' up', '.']
INFO:root:Predicted n-gram: [' small', ' amount', ' Bieber', 'Atlantic'], Target n-gram: [' play', ' there', '!"', ' Her']
INFO:root:Predicted n-gram: [' down', ' Dec', ' then', ' upon'], Target n-gram: ['>', '<|endoftext|>', 'Once', ' upon']
INFO:root:Predicted n-gram: [' down', ' Dec', ' then', ' upon'], Target n-gram: [' it', ' with', ' milk', '.']
INFO:root:Predicted n-gram: ['.', ' Native', ' >=', 'events'], Target n-gram: [' to', ' go', ' home', '.']
INFO:root:Predicted n-gram: ['.', ' Hawai', 'IAL', ' liaison'], Target n-gram: [' The', ' little', ' boy', ' was']
INFO:root:Predicted n-gram: [' small', ' amount', ' Bieber', 'RG'], Target n-gram: [' both', ' built', ' stacks', ' and']
INFO:root:Predicted n-gram: ['.', '<|endoftext|>', ' there', 'events'], Target n-gram: [' not', ' like', ' to', ' share']
INFO:root:Predicted n-gram: ['ş', 'Set', ',', 'of'], Target n-gram: [' It', ' was', ' shiny', ' and']
INFO:root:Predicted n-gram: [' leve', ' day', ',', ' Ober'], Target n-gram: [' end', ',', ' the', ' old']
INFO:root:Predicted n-gram: [' something', ' irrigation', 'emate', ' nano'], Target n-gram: [' the', ' park', '.', ' She']
INFO:root:Predicted n-gram: [' sprung', ' taco', ' AFC', ' taco'], Target n-gram: [' Tim', ' took', ' it', ' home']
INFO:root:Predicted n-gram: ['ş', ' day', ',', ' upon'], Target n-gram: [' outside', '.', ' She', ' saw']
INFO:root:Predicted n-gram: [' and', 'weapon', 'VERSION', 'events'], Target n-gram: [' day', ',', ' while', ' the']
INFO:root:Step 1101, Learning Rate: 0.000141647376590743
INFO:root:Entering gradient accumulation loop for step 1101
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0246, Head Loss: 0.1822
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0332, Head Loss: 0.1541
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0426, Head Loss: 0.1606
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0480, Head Loss: 0.1797
INFO:root:Final accum gradient norm after all heads: 0.0480, Total Loss: 21.6508, Average Loss: 5.4127
INFO:root:Step 1102, Learning Rate: 0.0001414156094739268
INFO:root:Entering gradient accumulation loop for step 1102
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0275, Head Loss: 0.1727
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0343, Head Loss: 0.1391
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0401, Head Loss: 0.1859
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0484, Head Loss: 0.1430
INFO:root:Final accum gradient norm after all heads: 0.0484, Total Loss: 20.5035, Average Loss: 5.1259
INFO:root:Step 1103, Learning Rate: 0.00014118386291682368
INFO:root:Entering gradient accumulation loop for step 1103
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0263, Head Loss: 0.1854
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0383, Head Loss: 0.1613
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0457, Head Loss: 0.1842
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0536, Head Loss: 0.1939
INFO:root:Final accum gradient norm after all heads: 0.0536, Total Loss: 23.1943, Average Loss: 5.7986
INFO:root:Step 1104, Learning Rate: 0.0001409521374744693
INFO:root:Entering gradient accumulation loop for step 1104
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0208, Head Loss: 0.1505
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0309, Head Loss: 0.1563
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0385, Head Loss: 0.1470
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0454, Head Loss: 0.1735
INFO:root:Final accum gradient norm after all heads: 0.0454, Total Loss: 20.0715, Average Loss: 5.0179
INFO:root:Step 1105, Learning Rate: 0.00014072043370184873
INFO:root:Entering gradient accumulation loop for step 1105
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0206, Head Loss: 0.1710
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0323, Head Loss: 0.1764
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0413, Head Loss: 0.1708
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0462, Head Loss: 0.1740
INFO:root:Final accum gradient norm after all heads: 0.0462, Total Loss: 22.1516, Average Loss: 5.5379
INFO:root:Step 1106, Learning Rate: 0.0001404887521538951
INFO:root:Entering gradient accumulation loop for step 1106
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0249, Head Loss: 0.1572
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0345, Head Loss: 0.1767
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0411, Head Loss: 0.1396
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0464, Head Loss: 0.1561
INFO:root:Final accum gradient norm after all heads: 0.0464, Total Loss: 20.1466, Average Loss: 5.0367
INFO:root:Step 1107, Learning Rate: 0.00014025709338548836
INFO:root:Entering gradient accumulation loop for step 1107
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0221, Head Loss: 0.1657
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0310, Head Loss: 0.1584
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0347, Head Loss: 0.1614
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0426, Head Loss: 0.1524
INFO:root:Final accum gradient norm after all heads: 0.0426, Total Loss: 20.4125, Average Loss: 5.1031
INFO:root:Step 1108, Learning Rate: 0.00014002545795145397
INFO:root:Entering gradient accumulation loop for step 1108
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0180, Head Loss: 0.1583
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0299, Head Loss: 0.1796
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0364, Head Loss: 0.1594
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0428, Head Loss: 0.1769
INFO:root:Final accum gradient norm after all heads: 0.0428, Total Loss: 21.5718, Average Loss: 5.3929
INFO:root:Step 1109, Learning Rate: 0.00013979384640656136
INFO:root:Entering gradient accumulation loop for step 1109
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0254, Head Loss: 0.1747
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0302, Head Loss: 0.1579
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0397, Head Loss: 0.1463
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0483, Head Loss: 0.1684
INFO:root:Final accum gradient norm after all heads: 0.0483, Total Loss: 20.7165, Average Loss: 5.1791
INFO:root:Step 1110, Learning Rate: 0.0001395622593055228
INFO:root:Entering gradient accumulation loop for step 1110
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0162, Head Loss: 0.1569
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0256, Head Loss: 0.1608
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0307, Head Loss: 0.1562
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0352, Head Loss: 0.1508
INFO:root:Final accum gradient norm after all heads: 0.0352, Total Loss: 19.9911, Average Loss: 4.9978
INFO:root:Step 1111, Learning Rate: 0.00013933069720299213
INFO:root:Entering gradient accumulation loop for step 1111
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0221, Head Loss: 0.1785
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0338, Head Loss: 0.1847
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0428, Head Loss: 0.1795
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0545, Head Loss: 0.2128
INFO:root:Final accum gradient norm after all heads: 0.0545, Total Loss: 24.1740, Average Loss: 6.0435
INFO:root:Step 1112, Learning Rate: 0.00013909916065356316
INFO:root:Entering gradient accumulation loop for step 1112
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0222, Head Loss: 0.1411
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0400, Head Loss: 0.1791
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0436, Head Loss: 0.1558
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0483, Head Loss: 0.1393
INFO:root:Final accum gradient norm after all heads: 0.0483, Total Loss: 19.6918, Average Loss: 4.9229
INFO:root:Step 1113, Learning Rate: 0.00013886765021176853
INFO:root:Entering gradient accumulation loop for step 1113
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0283, Head Loss: 0.1689
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0351, Head Loss: 0.1681
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0407, Head Loss: 0.1785
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0477, Head Loss: 0.1550
INFO:root:Final accum gradient norm after all heads: 0.0477, Total Loss: 21.4538, Average Loss: 5.3634
INFO:root:Step 1114, Learning Rate: 0.00013863616643207844
INFO:root:Entering gradient accumulation loop for step 1114
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0203, Head Loss: 0.1577
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0271, Head Loss: 0.1381
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0352, Head Loss: 0.1748
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0452, Head Loss: 0.1750
INFO:root:Final accum gradient norm after all heads: 0.0452, Total Loss: 20.6561, Average Loss: 5.1640
INFO:root:Step 1115, Learning Rate: 0.0001384047098688992
INFO:root:Entering gradient accumulation loop for step 1115
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0252, Head Loss: 0.1585
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0374, Head Loss: 0.1628
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0471, Head Loss: 0.1727
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0520, Head Loss: 0.1779
INFO:root:Final accum gradient norm after all heads: 0.0520, Total Loss: 21.5010, Average Loss: 5.3753
INFO:root:Step 1116, Learning Rate: 0.0001381732810765718
INFO:root:Entering gradient accumulation loop for step 1116
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0199, Head Loss: 0.1474
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0287, Head Loss: 0.1443
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0365, Head Loss: 0.1627
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0436, Head Loss: 0.1788
INFO:root:Final accum gradient norm after all heads: 0.0436, Total Loss: 20.2620, Average Loss: 5.0655
INFO:root:Step 1117, Learning Rate: 0.00013794188060937097
INFO:root:Entering gradient accumulation loop for step 1117
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0250, Head Loss: 0.1646
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0368, Head Loss: 0.1660
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0419, Head Loss: 0.1699
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0478, Head Loss: 0.1771
INFO:root:Final accum gradient norm after all heads: 0.0478, Total Loss: 21.6824, Average Loss: 5.4206
INFO:root:Step 1118, Learning Rate: 0.00013771050902150345
INFO:root:Entering gradient accumulation loop for step 1118
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0248, Head Loss: 0.1724
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0332, Head Loss: 0.1781
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0423, Head Loss: 0.1709
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0469, Head Loss: 0.1673
INFO:root:Final accum gradient norm after all heads: 0.0469, Total Loss: 22.0385, Average Loss: 5.5096
INFO:root:Step 1119, Learning Rate: 0.0001374791668671067
INFO:root:Entering gradient accumulation loop for step 1119
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0253, Head Loss: 0.1743
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0307, Head Loss: 0.1343
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0434, Head Loss: 0.1850
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0525, Head Loss: 0.1722
INFO:root:Final accum gradient norm after all heads: 0.0525, Total Loss: 21.3027, Average Loss: 5.3257
INFO:root:Step 1120, Learning Rate: 0.00013724785470024792
INFO:root:Entering gradient accumulation loop for step 1120
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0243, Head Loss: 0.1866
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0336, Head Loss: 0.1603
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0391, Head Loss: 0.1514
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0461, Head Loss: 0.1613
INFO:root:Final accum gradient norm after all heads: 0.0461, Total Loss: 21.1093, Average Loss: 5.2773
INFO:root:Step 1121, Learning Rate: 0.00013701657307492235
INFO:root:Entering gradient accumulation loop for step 1121
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0280, Head Loss: 0.1719
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0380, Head Loss: 0.1896
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0428, Head Loss: 0.1796
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0465, Head Loss: 0.1645
INFO:root:Final accum gradient norm after all heads: 0.0465, Total Loss: 22.5778, Average Loss: 5.6445
INFO:root:Step 1122, Learning Rate: 0.0001367853225450522
INFO:root:Entering gradient accumulation loop for step 1122
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0258, Head Loss: 0.1697
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0337, Head Loss: 0.1549
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0405, Head Loss: 0.1539
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0471, Head Loss: 0.1748
INFO:root:Final accum gradient norm after all heads: 0.0471, Total Loss: 20.9080, Average Loss: 5.2270
INFO:root:Step 1123, Learning Rate: 0.00013655410366448498
INFO:root:Entering gradient accumulation loop for step 1123
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0275, Head Loss: 0.1705
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0329, Head Loss: 0.1693
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0427, Head Loss: 0.1707
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0480, Head Loss: 0.1826
INFO:root:Final accum gradient norm after all heads: 0.0480, Total Loss: 22.1757, Average Loss: 5.5439
INFO:root:Step 1124, Learning Rate: 0.0001363229169869926
INFO:root:Entering gradient accumulation loop for step 1124
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0234, Head Loss: 0.1478
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0401, Head Loss: 0.1977
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0475, Head Loss: 0.1796
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0515, Head Loss: 0.1606
INFO:root:Final accum gradient norm after all heads: 0.0515, Total Loss: 21.9429, Average Loss: 5.4857
INFO:root:Step 1125, Learning Rate: 0.0001360917630662699
INFO:root:Entering gradient accumulation loop for step 1125
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0265, Head Loss: 0.1909
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0349, Head Loss: 0.1690
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0402, Head Loss: 0.1627
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0455, Head Loss: 0.1780
INFO:root:Final accum gradient norm after all heads: 0.0455, Total Loss: 22.4173, Average Loss: 5.6043
INFO:root:Step 1126, Learning Rate: 0.00013586064245593298
INFO:root:Entering gradient accumulation loop for step 1126
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0153, Head Loss: 0.1702
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0325, Head Loss: 0.1661
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0365, Head Loss: 0.1661
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0438, Head Loss: 0.1882
INFO:root:Final accum gradient norm after all heads: 0.0438, Total Loss: 22.1020, Average Loss: 5.5255
INFO:root:Step 1127, Learning Rate: 0.00013562955570951837
INFO:root:Entering gradient accumulation loop for step 1127
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0224, Head Loss: 0.1733
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0307, Head Loss: 0.1576
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0353, Head Loss: 0.1332
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0451, Head Loss: 0.1584
INFO:root:Final accum gradient norm after all heads: 0.0451, Total Loss: 19.9183, Average Loss: 4.9796
INFO:root:Step 1128, Learning Rate: 0.00013539850338048154
INFO:root:Entering gradient accumulation loop for step 1128
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0218, Head Loss: 0.1541
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0341, Head Loss: 0.1591
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0394, Head Loss: 0.1497
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0426, Head Loss: 0.1579
INFO:root:Final accum gradient norm after all heads: 0.0426, Total Loss: 19.8623, Average Loss: 4.9656
INFO:root:Step 1129, Learning Rate: 0.0001351674860221954
INFO:root:Entering gradient accumulation loop for step 1129
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0232, Head Loss: 0.1340
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0362, Head Loss: 0.1867
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0472, Head Loss: 0.1815
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0527, Head Loss: 0.1825
INFO:root:Final accum gradient norm after all heads: 0.0527, Total Loss: 21.9107, Average Loss: 5.4777
INFO:root:Step 1130, Learning Rate: 0.00013493650418794912
INFO:root:Entering gradient accumulation loop for step 1130
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0268, Head Loss: 0.1687
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0324, Head Loss: 0.1835
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0355, Head Loss: 0.1390
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0406, Head Loss: 0.1625
INFO:root:Final accum gradient norm after all heads: 0.0406, Total Loss: 20.9158, Average Loss: 5.2289
INFO:root:Step 1131, Learning Rate: 0.0001347055584309469
INFO:root:Entering gradient accumulation loop for step 1131
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0207, Head Loss: 0.1594
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0301, Head Loss: 0.1728
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0404, Head Loss: 0.1663
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0473, Head Loss: 0.1844
INFO:root:Final accum gradient norm after all heads: 0.0473, Total Loss: 21.8517, Average Loss: 5.4629
INFO:root:Step 1132, Learning Rate: 0.00013447464930430646
INFO:root:Entering gradient accumulation loop for step 1132
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0221, Head Loss: 0.1643
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0327, Head Loss: 0.1550
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0424, Head Loss: 0.1862
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0467, Head Loss: 0.1500
INFO:root:Final accum gradient norm after all heads: 0.0467, Total Loss: 20.9731, Average Loss: 5.2433
INFO:root:Step 1133, Learning Rate: 0.0001342437773610577
INFO:root:Entering gradient accumulation loop for step 1133
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0228, Head Loss: 0.1565
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0336, Head Loss: 0.1617
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0440, Head Loss: 0.2052
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0489, Head Loss: 0.1600
INFO:root:Final accum gradient norm after all heads: 0.0489, Total Loss: 21.8685, Average Loss: 5.4671
INFO:root:Step 1134, Learning Rate: 0.0001340129431541416
INFO:root:Entering gradient accumulation loop for step 1134
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0253, Head Loss: 0.1794
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0374, Head Loss: 0.1706
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0430, Head Loss: 0.1623
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0492, Head Loss: 0.1681
INFO:root:Final accum gradient norm after all heads: 0.0492, Total Loss: 21.7729, Average Loss: 5.4432
INFO:root:Step 1135, Learning Rate: 0.00013378214723640876
INFO:root:Entering gradient accumulation loop for step 1135
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0294, Head Loss: 0.1920
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0366, Head Loss: 0.1296
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0532, Head Loss: 0.2097
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0577, Head Loss: 0.1597
INFO:root:Final accum gradient norm after all heads: 0.0577, Total Loss: 22.1130, Average Loss: 5.5283
INFO:root:Step 1136, Learning Rate: 0.00013355139016061793
INFO:root:Entering gradient accumulation loop for step 1136
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0251, Head Loss: 0.1861
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0320, Head Loss: 0.1125
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0421, Head Loss: 0.1609
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0506, Head Loss: 0.1753
INFO:root:Final accum gradient norm after all heads: 0.0506, Total Loss: 20.3127, Average Loss: 5.0782
INFO:root:Step 1137, Learning Rate: 0.000133320672479435
INFO:root:Entering gradient accumulation loop for step 1137
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0216, Head Loss: 0.1639
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0300, Head Loss: 0.1430
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0418, Head Loss: 0.1791
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0452, Head Loss: 0.1504
INFO:root:Final accum gradient norm after all heads: 0.0452, Total Loss: 20.3677, Average Loss: 5.0919
INFO:root:Step 1138, Learning Rate: 0.0001330899947454315
INFO:root:Entering gradient accumulation loop for step 1138
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0200, Head Loss: 0.1618
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0363, Head Loss: 0.1797
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0450, Head Loss: 0.1899
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0509, Head Loss: 0.1694
INFO:root:Final accum gradient norm after all heads: 0.0509, Total Loss: 22.4214, Average Loss: 5.6053
INFO:root:Step 1139, Learning Rate: 0.0001328593575110831
INFO:root:Entering gradient accumulation loop for step 1139
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0151, Head Loss: 0.1561
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0234, Head Loss: 0.1309
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0286, Head Loss: 0.1557
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0330, Head Loss: 0.1490
INFO:root:Final accum gradient norm after all heads: 0.0330, Total Loss: 18.9332, Average Loss: 4.7333
INFO:root:Step 1140, Learning Rate: 0.00013262876132876867
INFO:root:Entering gradient accumulation loop for step 1140
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0201, Head Loss: 0.1795
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0282, Head Loss: 0.1550
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0395, Head Loss: 0.1748
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0455, Head Loss: 0.1678
INFO:root:Final accum gradient norm after all heads: 0.0455, Total Loss: 21.6664, Average Loss: 5.4166
INFO:root:Step 1141, Learning Rate: 0.00013239820675076867
INFO:root:Entering gradient accumulation loop for step 1141
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0231, Head Loss: 0.1618
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0292, Head Loss: 0.1412
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0351, Head Loss: 0.1469
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0412, Head Loss: 0.1651
INFO:root:Final accum gradient norm after all heads: 0.0412, Total Loss: 19.6802, Average Loss: 4.9200
INFO:root:Step 1142, Learning Rate: 0.00013216769432926404
INFO:root:Entering gradient accumulation loop for step 1142
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0236, Head Loss: 0.1651
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0305, Head Loss: 0.1598
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0398, Head Loss: 0.1623
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0528, Head Loss: 0.2037
INFO:root:Final accum gradient norm after all heads: 0.0528, Total Loss: 22.1055, Average Loss: 5.5264
INFO:root:Step 1143, Learning Rate: 0.0001319372246163345
INFO:root:Entering gradient accumulation loop for step 1143
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0248, Head Loss: 0.1728
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0297, Head Loss: 0.1607
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0367, Head Loss: 0.1705
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0452, Head Loss: 0.1685
INFO:root:Final accum gradient norm after all heads: 0.0452, Total Loss: 21.5219, Average Loss: 5.3805
INFO:root:Step 1144, Learning Rate: 0.00013170679816395774
INFO:root:Entering gradient accumulation loop for step 1144
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0301, Head Loss: 0.1650
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0360, Head Loss: 0.1499
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0467, Head Loss: 0.1892
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0516, Head Loss: 0.1430
INFO:root:Final accum gradient norm after all heads: 0.0516, Total Loss: 20.7057, Average Loss: 5.1764
INFO:root:Step 1145, Learning Rate: 0.00013147641552400778
INFO:root:Entering gradient accumulation loop for step 1145
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0218, Head Loss: 0.1492
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0334, Head Loss: 0.1887
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0408, Head Loss: 0.1665
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0447, Head Loss: 0.1795
INFO:root:Final accum gradient norm after all heads: 0.0447, Total Loss: 21.8842, Average Loss: 5.4711
INFO:root:Step 1146, Learning Rate: 0.0001312460772482535
INFO:root:Entering gradient accumulation loop for step 1146
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0229, Head Loss: 0.1757
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0284, Head Loss: 0.1538
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0424, Head Loss: 0.1786
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0469, Head Loss: 0.1601
INFO:root:Final accum gradient norm after all heads: 0.0469, Total Loss: 21.3823, Average Loss: 5.3456
INFO:root:Step 1147, Learning Rate: 0.00013101578388835782
INFO:root:Entering gradient accumulation loop for step 1147
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0258, Head Loss: 0.1632
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0330, Head Loss: 0.1594
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0396, Head Loss: 0.1532
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0459, Head Loss: 0.1705
INFO:root:Final accum gradient norm after all heads: 0.0459, Total Loss: 20.6812, Average Loss: 5.1703
INFO:root:Step 1148, Learning Rate: 0.00013078553599587593
INFO:root:Entering gradient accumulation loop for step 1148
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0186, Head Loss: 0.1471
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0280, Head Loss: 0.1652
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0352, Head Loss: 0.1564
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0423, Head Loss: 0.1619
INFO:root:Final accum gradient norm after all heads: 0.0423, Total Loss: 20.1789, Average Loss: 5.0447
INFO:root:Step 1149, Learning Rate: 0.00013055533412225422
INFO:root:Entering gradient accumulation loop for step 1149
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0196, Head Loss: 0.1650
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0305, Head Loss: 0.1918
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0411, Head Loss: 0.1782
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0513, Head Loss: 0.1752
INFO:root:Final accum gradient norm after all heads: 0.0513, Total Loss: 22.7236, Average Loss: 5.6809
INFO:root:Step 1150, Learning Rate: 0.00013032517881882865
INFO:root:Entering gradient accumulation loop for step 1150
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0329, Head Loss: 0.1820
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0397, Head Loss: 0.1419
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0454, Head Loss: 0.1557
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0476, Head Loss: 0.1501
INFO:root:Final accum gradient norm after all heads: 0.0476, Total Loss: 20.1489, Average Loss: 5.0372
INFO:root:Step 1150: Loss 5.04, Norm: 2.2371, Time: 33.09s, Tokens Seen: 291.2M
INFO:root:Step 1151, Learning Rate: 0.00013009507063682388
INFO:root:Entering gradient accumulation loop for step 1151
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0186, Head Loss: 0.1608
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0280, Head Loss: 0.1636
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0393, Head Loss: 0.1584
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0442, Head Loss: 0.1690
INFO:root:Final accum gradient norm after all heads: 0.0442, Total Loss: 20.8585, Average Loss: 5.2146
INFO:root:Step 1152, Learning Rate: 0.0001298650101273517
INFO:root:Entering gradient accumulation loop for step 1152
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0217, Head Loss: 0.1563
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0317, Head Loss: 0.1311
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0377, Head Loss: 0.1533
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0415, Head Loss: 0.1547
INFO:root:Final accum gradient norm after all heads: 0.0415, Total Loss: 19.0565, Average Loss: 4.7641
INFO:root:Step 1153, Learning Rate: 0.00012963499784140952
INFO:root:Entering gradient accumulation loop for step 1153
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0258, Head Loss: 0.1759
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0369, Head Loss: 0.1853
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0432, Head Loss: 0.1776
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0509, Head Loss: 0.1718
INFO:root:Final accum gradient norm after all heads: 0.0509, Total Loss: 22.7425, Average Loss: 5.6856
INFO:root:Step 1154, Learning Rate: 0.00012940503432987943
INFO:root:Entering gradient accumulation loop for step 1154
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0276, Head Loss: 0.1871
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0319, Head Loss: 0.1394
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0384, Head Loss: 0.1420
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0440, Head Loss: 0.1775
INFO:root:Final accum gradient norm after all heads: 0.0440, Total Loss: 20.6716, Average Loss: 5.1679
INFO:root:Step 1155, Learning Rate: 0.0001291751201435267
INFO:root:Entering gradient accumulation loop for step 1155
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0351, Head Loss: 0.1882
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0393, Head Loss: 0.1479
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0476, Head Loss: 0.1687
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0569, Head Loss: 0.1600
INFO:root:Final accum gradient norm after all heads: 0.0569, Total Loss: 21.2778, Average Loss: 5.3194
INFO:root:Step 1156, Learning Rate: 0.00012894525583299833
INFO:root:Entering gradient accumulation loop for step 1156
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0293, Head Loss: 0.1628
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0383, Head Loss: 0.1658
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0429, Head Loss: 0.1796
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0505, Head Loss: 0.1623
INFO:root:Final accum gradient norm after all heads: 0.0505, Total Loss: 21.4578, Average Loss: 5.3645
INFO:root:Step 1157, Learning Rate: 0.00012871544194882208
INFO:root:Entering gradient accumulation loop for step 1157
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0307, Head Loss: 0.1889
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0429, Head Loss: 0.1614
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0527, Head Loss: 0.1966
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0589, Head Loss: 0.1639
INFO:root:Final accum gradient norm after all heads: 0.0589, Total Loss: 22.7491, Average Loss: 5.6873
INFO:root:Step 1158, Learning Rate: 0.00012848567904140474
INFO:root:Entering gradient accumulation loop for step 1158
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0291, Head Loss: 0.1766
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0385, Head Loss: 0.1733
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0441, Head Loss: 0.2004
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0471, Head Loss: 0.1431
INFO:root:Final accum gradient norm after all heads: 0.0471, Total Loss: 22.1898, Average Loss: 5.5475
INFO:root:Step 1159, Learning Rate: 0.00012825596766103116
INFO:root:Entering gradient accumulation loop for step 1159
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0206, Head Loss: 0.1501
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0325, Head Loss: 0.1671
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0372, Head Loss: 0.1646
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0409, Head Loss: 0.1659
INFO:root:Final accum gradient norm after all heads: 0.0409, Total Loss: 20.7240, Average Loss: 5.1810
INFO:root:Step 1160, Learning Rate: 0.00012802630835786262
INFO:root:Entering gradient accumulation loop for step 1160
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0221, Head Loss: 0.1820
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0319, Head Loss: 0.1615
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0432, Head Loss: 0.1619
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0516, Head Loss: 0.1666
INFO:root:Final accum gradient norm after all heads: 0.0516, Total Loss: 21.5034, Average Loss: 5.3759
INFO:root:Step 1161, Learning Rate: 0.0001277967016819358
INFO:root:Entering gradient accumulation loop for step 1161
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0169, Head Loss: 0.1680
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0297, Head Loss: 0.1836
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0402, Head Loss: 0.1871
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0445, Head Loss: 0.1522
INFO:root:Final accum gradient norm after all heads: 0.0445, Total Loss: 22.1102, Average Loss: 5.5276
INFO:root:Step 1162, Learning Rate: 0.0001275671481831614
INFO:root:Entering gradient accumulation loop for step 1162
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0191, Head Loss: 0.1567
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0293, Head Loss: 0.1559
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0399, Head Loss: 0.1615
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0455, Head Loss: 0.1687
INFO:root:Final accum gradient norm after all heads: 0.0455, Total Loss: 20.5697, Average Loss: 5.1424
INFO:root:Step 1163, Learning Rate: 0.0001273376484113225
INFO:root:Entering gradient accumulation loop for step 1163
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0229, Head Loss: 0.1407
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0348, Head Loss: 0.1527
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0392, Head Loss: 0.1551
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0488, Head Loss: 0.1692
INFO:root:Final accum gradient norm after all heads: 0.0488, Total Loss: 19.7698, Average Loss: 4.9425
INFO:root:Step 1164, Learning Rate: 0.00012710820291607374
INFO:root:Entering gradient accumulation loop for step 1164
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0307, Head Loss: 0.1507
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0356, Head Loss: 0.1388
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0408, Head Loss: 0.1509
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0452, Head Loss: 0.1570
INFO:root:Final accum gradient norm after all heads: 0.0452, Total Loss: 19.1131, Average Loss: 4.7783
INFO:root:Step 1165, Learning Rate: 0.0001268788122469397
INFO:root:Entering gradient accumulation loop for step 1165
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0229, Head Loss: 0.1597
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0299, Head Loss: 0.1459
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0359, Head Loss: 0.1546
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0415, Head Loss: 0.1415
INFO:root:Final accum gradient norm after all heads: 0.0415, Total Loss: 19.2527, Average Loss: 4.8132
INFO:root:Step 1166, Learning Rate: 0.00012664947695331376
INFO:root:Entering gradient accumulation loop for step 1166
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0256, Head Loss: 0.1777
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0324, Head Loss: 0.1639
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0377, Head Loss: 0.1416
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0420, Head Loss: 0.1637
INFO:root:Final accum gradient norm after all heads: 0.0420, Total Loss: 20.7030, Average Loss: 5.1758
INFO:root:Step 1167, Learning Rate: 0.00012642019758445634
INFO:root:Entering gradient accumulation loop for step 1167
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0215, Head Loss: 0.1585
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0298, Head Loss: 0.1437
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0396, Head Loss: 0.1625
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0433, Head Loss: 0.1414
INFO:root:Final accum gradient norm after all heads: 0.0433, Total Loss: 19.3958, Average Loss: 4.8489
INFO:root:Step 1168, Learning Rate: 0.00012619097468949425
INFO:root:Entering gradient accumulation loop for step 1168
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0264, Head Loss: 0.1727
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0325, Head Loss: 0.1315
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0377, Head Loss: 0.1575
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0430, Head Loss: 0.1644
INFO:root:Final accum gradient norm after all heads: 0.0430, Total Loss: 20.0350, Average Loss: 5.0087
INFO:root:Step 1169, Learning Rate: 0.00012596180881741895
INFO:root:Entering gradient accumulation loop for step 1169
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0206, Head Loss: 0.1586
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0319, Head Loss: 0.1712
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0382, Head Loss: 0.1566
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0488, Head Loss: 0.1945
INFO:root:Final accum gradient norm after all heads: 0.0488, Total Loss: 21.7914, Average Loss: 5.4479
INFO:root:Step 1170, Learning Rate: 0.0001257327005170853
INFO:root:Entering gradient accumulation loop for step 1170
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0242, Head Loss: 0.1691
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0319, Head Loss: 0.1679
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0356, Head Loss: 0.1687
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0402, Head Loss: 0.1628
INFO:root:Final accum gradient norm after all heads: 0.0402, Total Loss: 21.3932, Average Loss: 5.3483
INFO:root:Step 1171, Learning Rate: 0.00012550365033721023
INFO:root:Entering gradient accumulation loop for step 1171
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0257, Head Loss: 0.1931
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0334, Head Loss: 0.1622
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0377, Head Loss: 0.1646
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0425, Head Loss: 0.1592
INFO:root:Final accum gradient norm after all heads: 0.0425, Total Loss: 21.7294, Average Loss: 5.4323
INFO:root:Step 1172, Learning Rate: 0.0001252746588263717
INFO:root:Entering gradient accumulation loop for step 1172
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0204, Head Loss: 0.1540
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0288, Head Loss: 0.1583
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0332, Head Loss: 0.1519
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0388, Head Loss: 0.1442
INFO:root:Final accum gradient norm after all heads: 0.0388, Total Loss: 19.4677, Average Loss: 4.8669
INFO:root:Step 1173, Learning Rate: 0.00012504572653300675
INFO:root:Entering gradient accumulation loop for step 1173
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0208, Head Loss: 0.1688
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0278, Head Loss: 0.1683
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0345, Head Loss: 0.1718
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0371, Head Loss: 0.1475
INFO:root:Final accum gradient norm after all heads: 0.0371, Total Loss: 21.0048, Average Loss: 5.2512
INFO:root:Step 1174, Learning Rate: 0.00012481685400541096
INFO:root:Entering gradient accumulation loop for step 1174
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0213, Head Loss: 0.1674
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0322, Head Loss: 0.1682
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0364, Head Loss: 0.1623
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0422, Head Loss: 0.1593
INFO:root:Final accum gradient norm after all heads: 0.0422, Total Loss: 21.0311, Average Loss: 5.2578
INFO:root:Step 1175, Learning Rate: 0.00012458804179173668
INFO:root:Entering gradient accumulation loop for step 1175
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0194, Head Loss: 0.1485
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0297, Head Loss: 0.1727
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0380, Head Loss: 0.1679
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0470, Head Loss: 0.1671
INFO:root:Final accum gradient norm after all heads: 0.0470, Total Loss: 20.9986, Average Loss: 5.2497
INFO:root:Step 1176, Learning Rate: 0.00012435929043999174
INFO:root:Entering gradient accumulation loop for step 1176
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0250, Head Loss: 0.1891
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0351, Head Loss: 0.1668
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0415, Head Loss: 0.1804
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0464, Head Loss: 0.1589
INFO:root:Final accum gradient norm after all heads: 0.0464, Total Loss: 22.2441, Average Loss: 5.5610
INFO:root:Step 1177, Learning Rate: 0.00012413060049803814
INFO:root:Entering gradient accumulation loop for step 1177
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0229, Head Loss: 0.1642
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0359, Head Loss: 0.1739
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0427, Head Loss: 0.1796
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0487, Head Loss: 0.1562
INFO:root:Final accum gradient norm after all heads: 0.0487, Total Loss: 21.5630, Average Loss: 5.3908
INFO:root:Step 1178, Learning Rate: 0.00012390197251359097
INFO:root:Entering gradient accumulation loop for step 1178
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0187, Head Loss: 0.1614
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0309, Head Loss: 0.1688
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0405, Head Loss: 0.1671
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0459, Head Loss: 0.1706
INFO:root:Final accum gradient norm after all heads: 0.0459, Total Loss: 21.3733, Average Loss: 5.3433
INFO:root:Step 1179, Learning Rate: 0.0001236734070342169
INFO:root:Entering gradient accumulation loop for step 1179
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0238, Head Loss: 0.1612
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0286, Head Loss: 0.1534
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0360, Head Loss: 0.1667
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0412, Head Loss: 0.1801
INFO:root:Final accum gradient norm after all heads: 0.0412, Total Loss: 21.1622, Average Loss: 5.2906
INFO:root:Step 1180, Learning Rate: 0.00012344490460733276
INFO:root:Entering gradient accumulation loop for step 1180
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0228, Head Loss: 0.1342
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0353, Head Loss: 0.1790
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0419, Head Loss: 0.1697
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0494, Head Loss: 0.1613
INFO:root:Final accum gradient norm after all heads: 0.0494, Total Loss: 20.6123, Average Loss: 5.1531
INFO:root:Step 1181, Learning Rate: 0.0001232164657802045
INFO:root:Entering gradient accumulation loop for step 1181
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0249, Head Loss: 0.1983
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0334, Head Loss: 0.1630
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0429, Head Loss: 0.1722
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0487, Head Loss: 0.1628
INFO:root:Final accum gradient norm after all heads: 0.0487, Total Loss: 22.2812, Average Loss: 5.5703
INFO:root:Step 1182, Learning Rate: 0.00012298809109994574
INFO:root:Entering gradient accumulation loop for step 1182
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0200, Head Loss: 0.1648
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0280, Head Loss: 0.1346
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0338, Head Loss: 0.1606
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0420, Head Loss: 0.1308
INFO:root:Final accum gradient norm after all heads: 0.0420, Total Loss: 18.9043, Average Loss: 4.7261
INFO:root:Step 1183, Learning Rate: 0.00012275978111351643
INFO:root:Entering gradient accumulation loop for step 1183
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0216, Head Loss: 0.1648
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0321, Head Loss: 0.1480
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0358, Head Loss: 0.1488
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0423, Head Loss: 0.1655
INFO:root:Final accum gradient norm after all heads: 0.0423, Total Loss: 20.0718, Average Loss: 5.0179
INFO:root:Step 1184, Learning Rate: 0.00012253153636772156
INFO:root:Entering gradient accumulation loop for step 1184
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0281, Head Loss: 0.2059
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0321, Head Loss: 0.1555
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0386, Head Loss: 0.1577
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0480, Head Loss: 0.2052
INFO:root:Final accum gradient norm after all heads: 0.0480, Total Loss: 23.1798, Average Loss: 5.7950
INFO:root:Step 1185, Learning Rate: 0.00012230335740920996
INFO:root:Entering gradient accumulation loop for step 1185
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0202, Head Loss: 0.1567
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0314, Head Loss: 0.1781
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0363, Head Loss: 0.1575
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0443, Head Loss: 0.1846
INFO:root:Final accum gradient norm after all heads: 0.0443, Total Loss: 21.6607, Average Loss: 5.4152
INFO:root:Step 1186, Learning Rate: 0.0001220752447844728
INFO:root:Entering gradient accumulation loop for step 1186
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0214, Head Loss: 0.1573
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0397, Head Loss: 0.2034
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0454, Head Loss: 0.1550
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0505, Head Loss: 0.1713
INFO:root:Final accum gradient norm after all heads: 0.0505, Total Loss: 21.9824, Average Loss: 5.4956
INFO:root:Step 1187, Learning Rate: 0.00012184719903984235
INFO:root:Entering gradient accumulation loop for step 1187
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0237, Head Loss: 0.1687
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0309, Head Loss: 0.1561
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0376, Head Loss: 0.1734
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0414, Head Loss: 0.1801
INFO:root:Final accum gradient norm after all heads: 0.0414, Total Loss: 21.7042, Average Loss: 5.4261
INFO:root:Step 1188, Learning Rate: 0.00012161922072149081
INFO:root:Entering gradient accumulation loop for step 1188
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0198, Head Loss: 0.1756
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0274, Head Loss: 0.1750
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0347, Head Loss: 0.1573
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0433, Head Loss: 0.1943
INFO:root:Final accum gradient norm after all heads: 0.0433, Total Loss: 22.4702, Average Loss: 5.6176
INFO:root:Step 1189, Learning Rate: 0.00012139131037542893
INFO:root:Entering gradient accumulation loop for step 1189
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0200, Head Loss: 0.1574
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0316, Head Loss: 0.1660
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0418, Head Loss: 0.1841
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0469, Head Loss: 0.1608
INFO:root:Final accum gradient norm after all heads: 0.0469, Total Loss: 21.3859, Average Loss: 5.3465
INFO:root:Step 1190, Learning Rate: 0.00012116346854750447
INFO:root:Entering gradient accumulation loop for step 1190
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0234, Head Loss: 0.1812
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0297, Head Loss: 0.1586
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0358, Head Loss: 0.1421
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0389, Head Loss: 0.1497
INFO:root:Final accum gradient norm after all heads: 0.0389, Total Loss: 20.2141, Average Loss: 5.0535
INFO:root:Step 1191, Learning Rate: 0.00012093569578340124
INFO:root:Entering gradient accumulation loop for step 1191
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0227, Head Loss: 0.1613
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0306, Head Loss: 0.1682
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0347, Head Loss: 0.1715
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0405, Head Loss: 0.1695
INFO:root:Final accum gradient norm after all heads: 0.0405, Total Loss: 21.4584, Average Loss: 5.3646
INFO:root:Step 1192, Learning Rate: 0.0001207079926286376
INFO:root:Entering gradient accumulation loop for step 1192
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0261, Head Loss: 0.1601
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0348, Head Loss: 0.1488
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0435, Head Loss: 0.1580
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0498, Head Loss: 0.1629
INFO:root:Final accum gradient norm after all heads: 0.0498, Total Loss: 20.1514, Average Loss: 5.0379
INFO:root:Step 1193, Learning Rate: 0.00012048035962856529
INFO:root:Entering gradient accumulation loop for step 1193
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0222, Head Loss: 0.1826
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0271, Head Loss: 0.1536
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0359, Head Loss: 0.1726
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0419, Head Loss: 0.1838
INFO:root:Final accum gradient norm after all heads: 0.0419, Total Loss: 22.1603, Average Loss: 5.5401
INFO:root:Step 1194, Learning Rate: 0.00012025279732836777
INFO:root:Entering gradient accumulation loop for step 1194
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0219, Head Loss: 0.1632
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0391, Head Loss: 0.2014
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0449, Head Loss: 0.1754
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0506, Head Loss: 0.1664
INFO:root:Final accum gradient norm after all heads: 0.0506, Total Loss: 22.6068, Average Loss: 5.6517
INFO:root:Step 1195, Learning Rate: 0.00012002530627305943
INFO:root:Entering gradient accumulation loop for step 1195
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0225, Head Loss: 0.1519
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0303, Head Loss: 0.1649
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0355, Head Loss: 0.1584
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0410, Head Loss: 0.1610
INFO:root:Final accum gradient norm after all heads: 0.0410, Total Loss: 20.3598, Average Loss: 5.0900
INFO:root:Step 1196, Learning Rate: 0.00011979788700748399
INFO:root:Entering gradient accumulation loop for step 1196
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0234, Head Loss: 0.1826
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0339, Head Loss: 0.1919
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0442, Head Loss: 0.1687
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0475, Head Loss: 0.1519
INFO:root:Final accum gradient norm after all heads: 0.0475, Total Loss: 22.2396, Average Loss: 5.5599
INFO:root:Step 1197, Learning Rate: 0.00011957054007631308
INFO:root:Entering gradient accumulation loop for step 1197
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0221, Head Loss: 0.1544
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0305, Head Loss: 0.1596
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0355, Head Loss: 0.1679
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0402, Head Loss: 0.1592
INFO:root:Final accum gradient norm after all heads: 0.0402, Total Loss: 20.5155, Average Loss: 5.1289
INFO:root:Step 1198, Learning Rate: 0.00011934326602404528
INFO:root:Entering gradient accumulation loop for step 1198
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0238, Head Loss: 0.1831
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0316, Head Loss: 0.1513
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0376, Head Loss: 0.1407
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0408, Head Loss: 0.1554
INFO:root:Final accum gradient norm after all heads: 0.0408, Total Loss: 20.1732, Average Loss: 5.0433
INFO:root:Step 1199, Learning Rate: 0.00011911606539500445
INFO:root:Entering gradient accumulation loop for step 1199
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0183, Head Loss: 0.1394
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0330, Head Loss: 0.1590
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0425, Head Loss: 0.1944
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0483, Head Loss: 0.1524
INFO:root:Final accum gradient norm after all heads: 0.0483, Total Loss: 20.6440, Average Loss: 5.1610
INFO:root:Step 1200, Learning Rate: 0.00011888893873333873
INFO:root:Eval Step 1200 across 50 batches (0.8M Tokens): Train Loss 10.7188, Val Loss 10.7199
INFO:root:Entering gradient accumulation loop for step 1200
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0239, Head Loss: 0.1723
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0290, Head Loss: 0.1626
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0349, Head Loss: 0.1580
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0411, Head Loss: 0.1455
INFO:root:Final accum gradient norm after all heads: 0.0411, Total Loss: 20.4283, Average Loss: 5.1071
INFO:root:Step 1200: Loss 5.11, Norm: 2.0565, Time: 47.92s, Tokens Seen: 304.3M
INFO:root:Predicted n-gram: [' Ginger', 'tains', ' Force', ' taco'], Target n-gram: ['of', 'text', '|', '>']
INFO:root:Predicted n-gram: [' ther', 'tains', ' provoked', 'ications'], Target n-gram: [' blanket', ' over', ' her', '.']
INFO:root:Predicted n-gram: [' Regulation', ' Announce', 'acts', ' Ober'], Target n-gram: [' "', 'Please', ',', ' loud']
INFO:root:Predicted n-gram: [' and', ' students', ' upon', ' grou'], Target n-gram: [' wanted', ' to', ' use', ' it']
INFO:root:Predicted n-gram: [' decided', '225', ' there', '"'], Target n-gram: [' let', ' go', ' of', ' my']
INFO:root:Predicted n-gram: [' small', ' coercive', ' provoked', ' 1934'], Target n-gram: [' the', ' top', '.', '\n']
INFO:root:Predicted n-gram: ['text', ' you', ' that', ' was'], Target n-gram: [' around', ' his', ' arm', '.']
INFO:root:Predicted n-gram: [' dust', 'tains', ' Bieber', ' Tal'], Target n-gram: [' and', ' Sam', ' were', ' brothers']
INFO:root:Predicted n-gram: ['>', ' you', ' a', 'events'], Target n-gram: [' made', ' the', ' town', ' very']
INFO:root:Predicted n-gram: [' and', ' ItemLevel', 'IAL', ' liaison'], Target n-gram: ['.', '\n', 'Tim', ' wanted']
INFO:root:Predicted n-gram: ['>', ' went', ' not', ' Ginger'], Target n-gram: ['You', ' destroyed', ' our', ' castle']
INFO:root:Predicted n-gram: ['ş', ' day', ',', ' upon'], Target n-gram: ['of', 'text', '|', '>']
INFO:root:Predicted n-gram: ['ş', ' day', ',', ' upon'], Target n-gram: ['usted', ' the', ' shelves', ' carefully']
INFO:root:Predicted n-gram: ['|', ' ItemLevel', '<|endoftext|>', 'events'], Target n-gram: [' It', ' could', ' break', ' very']
INFO:root:Predicted n-gram: ['.', ' taco', ' >=', ' liaison'], Target n-gram: [' f', 'auc', 'et', ' off']
INFO:root:Predicted n-gram: [' and', ' aerobic', ' a', ' grou'], Target n-gram: [',', ' Sue', ' and', ' her']
INFO:root:Predicted n-gram: [' ther', ' proficiency', 'swing', ' taco'], Target n-gram: [',', ' Sara', ' found', ' a']
INFO:root:Predicted n-gram: [' ey', ' Economy', ' then', ' Jim'], Target n-gram: ['end', 'of', 'text', '|']
INFO:root:Predicted n-gram: [' upon', ' the', '.', '|'], Target n-gram: [' a', ' while', ',', ' they']
INFO:root:Predicted n-gram: ['>', '>', '.', 'Once'], Target n-gram: [' ground', ' to', ' get', ' this']
INFO:root:Predicted n-gram: [' and', ' there', ' there', ' was'], Target n-gram: [' fell', ' down', '.', ' As']
INFO:root:Predicted n-gram: [' Regulation', ' Announce', 'acts', ' Ober'], Target n-gram: [' Tim', ' thought', ' about', ' it']
INFO:root:Predicted n-gram: ['.', 'weapon', ' Swe', 'Atlantic'], Target n-gram: [' to', ' another', '.', ' They']
INFO:root:Predicted n-gram: [' and', ' you', ' there', ' water'], Target n-gram: [' and', ' had', ' lots', ' of']
INFO:root:Predicted n-gram: [' decided', '225', ' there', '"'], Target n-gram: ['ido', ' was', ' very', ' excited']
INFO:root:Predicted n-gram: [' worked', ' irrigation', ' older', ' nano'], Target n-gram: ['?"', ' Her', ' mom', ' smiled']
INFO:root:Predicted n-gram: ['>', 'este', ' not', ' Helic'], Target n-gram: [',', ' I', ' want', ' to']
INFO:root:Predicted n-gram: ['|', '|', ' upon', ' Mother'], Target n-gram: ['|', '>', '<|endoftext|>', 'Once']
INFO:root:Predicted n-gram: [' and', 'site', ' there', '010'], Target n-gram: ['.', ' Fin', ' said', ',']
INFO:root:Predicted n-gram: [' decided', '225', ' there', '"'], Target n-gram: [' it', ' flew', ' down', ' to']
INFO:root:Predicted n-gram: ['text', ' and', 'Once', ' play'], Target n-gram: ['.', ' The', ' door', ' opened']
INFO:root:Predicted n-gram: [' small', ' amount', 'angering', 'save'], Target n-gram: [' the', ' honey', '.', ' He']
INFO:root:Step 1201, Learning Rate: 0.00011866188658301904
INFO:root:Entering gradient accumulation loop for step 1201
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0289, Head Loss: 0.1777
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0353, Head Loss: 0.1535
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0436, Head Loss: 0.1695
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0508, Head Loss: 0.1815
INFO:root:Final accum gradient norm after all heads: 0.0508, Total Loss: 21.8321, Average Loss: 5.4580
INFO:root:Step 1202, Learning Rate: 0.0001184349094878379
INFO:root:Entering gradient accumulation loop for step 1202
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0172, Head Loss: 0.1560
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0310, Head Loss: 0.1644
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0434, Head Loss: 0.1564
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0492, Head Loss: 0.1564
INFO:root:Final accum gradient norm after all heads: 0.0492, Total Loss: 20.2627, Average Loss: 5.0657
INFO:root:Step 1203, Learning Rate: 0.00011820800799140808
INFO:root:Entering gradient accumulation loop for step 1203
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0206, Head Loss: 0.1488
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0293, Head Loss: 0.1643
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0407, Head Loss: 0.1634
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0493, Head Loss: 0.1590
INFO:root:Final accum gradient norm after all heads: 0.0493, Total Loss: 20.3323, Average Loss: 5.0831
INFO:root:Step 1204, Learning Rate: 0.00011798118263716113
INFO:root:Entering gradient accumulation loop for step 1204
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0180, Head Loss: 0.1617
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0252, Head Loss: 0.1701
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0334, Head Loss: 0.1489
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0420, Head Loss: 0.1810
INFO:root:Final accum gradient norm after all heads: 0.0420, Total Loss: 21.1755, Average Loss: 5.2939
INFO:root:Step 1205, Learning Rate: 0.00011775443396834638
INFO:root:Entering gradient accumulation loop for step 1205
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0186, Head Loss: 0.1391
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0324, Head Loss: 0.1513
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0416, Head Loss: 0.1695
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0483, Head Loss: 0.1655
INFO:root:Final accum gradient norm after all heads: 0.0483, Total Loss: 20.0105, Average Loss: 5.0026
INFO:root:Step 1206, Learning Rate: 0.00011752776252802958
INFO:root:Entering gradient accumulation loop for step 1206
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0291, Head Loss: 0.2020
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0345, Head Loss: 0.1766
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0449, Head Loss: 0.1724
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0503, Head Loss: 0.1948
INFO:root:Final accum gradient norm after all heads: 0.0503, Total Loss: 23.8631, Average Loss: 5.9658
INFO:root:Step 1207, Learning Rate: 0.00011730116885909128
INFO:root:Entering gradient accumulation loop for step 1207
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0159, Head Loss: 0.1477
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0284, Head Loss: 0.1923
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0367, Head Loss: 0.1542
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0491, Head Loss: 0.1920
INFO:root:Final accum gradient norm after all heads: 0.0491, Total Loss: 21.9570, Average Loss: 5.4893
INFO:root:Step 1208, Learning Rate: 0.00011707465350422596
INFO:root:Entering gradient accumulation loop for step 1208
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0202, Head Loss: 0.1722
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0287, Head Loss: 0.1575
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0414, Head Loss: 0.1643
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0445, Head Loss: 0.1568
INFO:root:Final accum gradient norm after all heads: 0.0445, Total Loss: 20.8253, Average Loss: 5.2063
INFO:root:Step 1209, Learning Rate: 0.00011684821700594048
INFO:root:Entering gradient accumulation loop for step 1209
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0213, Head Loss: 0.1462
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0284, Head Loss: 0.1426
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0393, Head Loss: 0.1691
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0454, Head Loss: 0.1603
INFO:root:Final accum gradient norm after all heads: 0.0454, Total Loss: 19.7784, Average Loss: 4.9446
INFO:root:Step 1210, Learning Rate: 0.00011662185990655284
INFO:root:Entering gradient accumulation loop for step 1210
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0236, Head Loss: 0.1384
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0332, Head Loss: 0.1411
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0393, Head Loss: 0.1632
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0448, Head Loss: 0.1813
INFO:root:Final accum gradient norm after all heads: 0.0448, Total Loss: 19.9690, Average Loss: 4.9922
INFO:root:Step 1211, Learning Rate: 0.00011639558274819086
INFO:root:Entering gradient accumulation loop for step 1211
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0251, Head Loss: 0.1644
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0371, Head Loss: 0.1559
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0492, Head Loss: 0.2013
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0580, Head Loss: 0.1879
INFO:root:Final accum gradient norm after all heads: 0.0580, Total Loss: 22.7063, Average Loss: 5.6766
INFO:root:Step 1212, Learning Rate: 0.00011616938607279086
INFO:root:Entering gradient accumulation loop for step 1212
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0287, Head Loss: 0.1899
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0399, Head Loss: 0.1853
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0447, Head Loss: 0.1759
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0532, Head Loss: 0.1718
INFO:root:Final accum gradient norm after all heads: 0.0532, Total Loss: 23.1334, Average Loss: 5.7833
INFO:root:Step 1213, Learning Rate: 0.00011594327042209655
INFO:root:Entering gradient accumulation loop for step 1213
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0318, Head Loss: 0.1709
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0379, Head Loss: 0.1570
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0460, Head Loss: 0.1849
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0545, Head Loss: 0.1877
INFO:root:Final accum gradient norm after all heads: 0.0545, Total Loss: 22.4135, Average Loss: 5.6034
INFO:root:Step 1214, Learning Rate: 0.00011571723633765739
INFO:root:Entering gradient accumulation loop for step 1214
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0252, Head Loss: 0.1752
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0389, Head Loss: 0.1778
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0466, Head Loss: 0.1942
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0505, Head Loss: 0.1409
INFO:root:Final accum gradient norm after all heads: 0.0505, Total Loss: 22.0211, Average Loss: 5.5053
INFO:root:Step 1215, Learning Rate: 0.00011549128436082765
INFO:root:Entering gradient accumulation loop for step 1215
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0205, Head Loss: 0.1610
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0332, Head Loss: 0.1856
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0380, Head Loss: 0.1551
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0458, Head Loss: 0.1817
INFO:root:Final accum gradient norm after all heads: 0.0458, Total Loss: 21.8693, Average Loss: 5.4673
INFO:root:Step 1216, Learning Rate: 0.00011526541503276487
INFO:root:Entering gradient accumulation loop for step 1216
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0232, Head Loss: 0.1624
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0294, Head Loss: 0.1562
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0379, Head Loss: 0.1373
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0422, Head Loss: 0.1631
INFO:root:Final accum gradient norm after all heads: 0.0422, Total Loss: 19.8080, Average Loss: 4.9520
INFO:root:Step 1217, Learning Rate: 0.00011503962889442872
INFO:root:Entering gradient accumulation loop for step 1217
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0235, Head Loss: 0.1663
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0315, Head Loss: 0.1536
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0411, Head Loss: 0.1814
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0452, Head Loss: 0.1558
INFO:root:Final accum gradient norm after all heads: 0.0452, Total Loss: 21.0259, Average Loss: 5.2565
INFO:root:Step 1218, Learning Rate: 0.00011481392648657946
INFO:root:Entering gradient accumulation loop for step 1218
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0298, Head Loss: 0.1933
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0425, Head Loss: 0.1916
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0457, Head Loss: 0.1638
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0511, Head Loss: 0.1897
INFO:root:Final accum gradient norm after all heads: 0.0511, Total Loss: 23.6294, Average Loss: 5.9073
INFO:root:Step 1219, Learning Rate: 0.00011458830834977698
INFO:root:Entering gradient accumulation loop for step 1219
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0173, Head Loss: 0.1334
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0253, Head Loss: 0.1615
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0369, Head Loss: 0.1609
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0407, Head Loss: 0.1529
INFO:root:Final accum gradient norm after all heads: 0.0407, Total Loss: 19.4810, Average Loss: 4.8702
INFO:root:Step 1220, Learning Rate: 0.00011436277502437935
INFO:root:Entering gradient accumulation loop for step 1220
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0282, Head Loss: 0.1887
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0340, Head Loss: 0.1429
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0446, Head Loss: 0.1876
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0480, Head Loss: 0.1468
INFO:root:Final accum gradient norm after all heads: 0.0480, Total Loss: 21.3102, Average Loss: 5.3276
INFO:root:Step 1221, Learning Rate: 0.00011413732705054133
INFO:root:Entering gradient accumulation loop for step 1221
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0299, Head Loss: 0.1894
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0378, Head Loss: 0.1493
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0432, Head Loss: 0.1807
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0475, Head Loss: 0.1819
INFO:root:Final accum gradient norm after all heads: 0.0475, Total Loss: 22.4388, Average Loss: 5.6097
INFO:root:Step 1222, Learning Rate: 0.00011391196496821348
INFO:root:Entering gradient accumulation loop for step 1222
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0191, Head Loss: 0.1733
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0347, Head Loss: 0.1662
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0393, Head Loss: 0.1450
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0516, Head Loss: 0.1924
INFO:root:Final accum gradient norm after all heads: 0.0516, Total Loss: 21.6597, Average Loss: 5.4149
INFO:root:Step 1223, Learning Rate: 0.00011368668931714051
INFO:root:Entering gradient accumulation loop for step 1223
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0196, Head Loss: 0.1737
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0249, Head Loss: 0.1339
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0366, Head Loss: 0.1900
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0422, Head Loss: 0.1422
INFO:root:Final accum gradient norm after all heads: 0.0422, Total Loss: 20.4736, Average Loss: 5.1184
INFO:root:Step 1224, Learning Rate: 0.00011346150063686018
INFO:root:Entering gradient accumulation loop for step 1224
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0247, Head Loss: 0.1725
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0317, Head Loss: 0.1741
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0383, Head Loss: 0.1306
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0493, Head Loss: 0.1760
INFO:root:Final accum gradient norm after all heads: 0.0493, Total Loss: 20.9057, Average Loss: 5.2264
INFO:root:Step 1225, Learning Rate: 0.00011323639946670197
INFO:root:Entering gradient accumulation loop for step 1225
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0231, Head Loss: 0.1753
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0368, Head Loss: 0.1816
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0436, Head Loss: 0.1881
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0466, Head Loss: 0.1779
INFO:root:Final accum gradient norm after all heads: 0.0466, Total Loss: 23.1317, Average Loss: 5.7829
INFO:root:Step 1226, Learning Rate: 0.0001130113863457857
INFO:root:Entering gradient accumulation loop for step 1226
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0173, Head Loss: 0.1321
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0344, Head Loss: 0.1792
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0445, Head Loss: 0.1756
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0490, Head Loss: 0.1764
INFO:root:Final accum gradient norm after all heads: 0.0490, Total Loss: 21.2263, Average Loss: 5.3066
INFO:root:Step 1227, Learning Rate: 0.0001127864618130204
INFO:root:Entering gradient accumulation loop for step 1227
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0200, Head Loss: 0.1630
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0263, Head Loss: 0.1548
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0335, Head Loss: 0.1689
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0408, Head Loss: 0.1680
INFO:root:Final accum gradient norm after all heads: 0.0408, Total Loss: 20.9516, Average Loss: 5.2379
INFO:root:Step 1228, Learning Rate: 0.00011256162640710285
INFO:root:Entering gradient accumulation loop for step 1228
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0264, Head Loss: 0.1654
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0352, Head Loss: 0.1497
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0427, Head Loss: 0.1709
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0489, Head Loss: 0.1442
INFO:root:Final accum gradient norm after all heads: 0.0489, Total Loss: 20.1639, Average Loss: 5.0410
INFO:root:Step 1229, Learning Rate: 0.00011233688066651641
INFO:root:Entering gradient accumulation loop for step 1229
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0292, Head Loss: 0.1856
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0388, Head Loss: 0.1760
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0461, Head Loss: 0.1515
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0530, Head Loss: 0.1990
INFO:root:Final accum gradient norm after all heads: 0.0530, Total Loss: 22.7841, Average Loss: 5.6960
INFO:root:Step 1230, Learning Rate: 0.00011211222512952976
INFO:root:Entering gradient accumulation loop for step 1230
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0259, Head Loss: 0.1718
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0390, Head Loss: 0.1671
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0471, Head Loss: 0.1485
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0527, Head Loss: 0.1430
INFO:root:Final accum gradient norm after all heads: 0.0527, Total Loss: 20.1775, Average Loss: 5.0444
INFO:root:Step 1231, Learning Rate: 0.00011188766033419537
INFO:root:Entering gradient accumulation loop for step 1231
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0199, Head Loss: 0.1833
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0286, Head Loss: 0.1701
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0353, Head Loss: 0.1615
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0413, Head Loss: 0.1610
INFO:root:Final accum gradient norm after all heads: 0.0413, Total Loss: 21.6292, Average Loss: 5.4073
INFO:root:Step 1232, Learning Rate: 0.00011166318681834853
INFO:root:Entering gradient accumulation loop for step 1232
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0234, Head Loss: 0.1725
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0342, Head Loss: 0.1716
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0447, Head Loss: 0.1878
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0552, Head Loss: 0.2209
INFO:root:Final accum gradient norm after all heads: 0.0552, Total Loss: 24.0911, Average Loss: 6.0228
INFO:root:Step 1233, Learning Rate: 0.00011143880511960584
INFO:root:Entering gradient accumulation loop for step 1233
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0229, Head Loss: 0.1771
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0312, Head Loss: 0.1659
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0397, Head Loss: 0.1592
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0515, Head Loss: 0.1780
INFO:root:Final accum gradient norm after all heads: 0.0515, Total Loss: 21.7694, Average Loss: 5.4424
INFO:root:Step 1234, Learning Rate: 0.00011121451577536415
INFO:root:Entering gradient accumulation loop for step 1234
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0276, Head Loss: 0.1642
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0354, Head Loss: 0.1697
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0403, Head Loss: 0.1642
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0469, Head Loss: 0.1681
INFO:root:Final accum gradient norm after all heads: 0.0469, Total Loss: 21.3157, Average Loss: 5.3289
INFO:root:Step 1235, Learning Rate: 0.00011099031932279879
INFO:root:Entering gradient accumulation loop for step 1235
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0224, Head Loss: 0.1865
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0372, Head Loss: 0.1699
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0423, Head Loss: 0.1804
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0497, Head Loss: 0.2012
INFO:root:Final accum gradient norm after all heads: 0.0497, Total Loss: 23.6154, Average Loss: 5.9039
INFO:root:Step 1236, Learning Rate: 0.00011076621629886291
INFO:root:Entering gradient accumulation loop for step 1236
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0227, Head Loss: 0.1571
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0280, Head Loss: 0.1465
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0344, Head Loss: 0.1308
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0394, Head Loss: 0.1504
INFO:root:Final accum gradient norm after all heads: 0.0394, Total Loss: 18.7140, Average Loss: 4.6785
INFO:root:Step 1237, Learning Rate: 0.00011054220724028587
INFO:root:Entering gradient accumulation loop for step 1237
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0280, Head Loss: 0.1787
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0357, Head Loss: 0.1475
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0442, Head Loss: 0.2043
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0498, Head Loss: 0.1687
INFO:root:Final accum gradient norm after all heads: 0.0498, Total Loss: 22.3787, Average Loss: 5.5947
INFO:root:Step 1238, Learning Rate: 0.00011031829268357185
INFO:root:Entering gradient accumulation loop for step 1238
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0185, Head Loss: 0.1557
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0260, Head Loss: 0.1651
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0370, Head Loss: 0.1794
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0435, Head Loss: 0.1855
INFO:root:Final accum gradient norm after all heads: 0.0435, Total Loss: 21.9401, Average Loss: 5.4850
INFO:root:Step 1239, Learning Rate: 0.00011009447316499873
INFO:root:Entering gradient accumulation loop for step 1239
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0227, Head Loss: 0.1591
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0310, Head Loss: 0.1550
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0368, Head Loss: 0.1613
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0424, Head Loss: 0.1617
INFO:root:Final accum gradient norm after all heads: 0.0424, Total Loss: 20.3840, Average Loss: 5.0960
INFO:root:Step 1240, Learning Rate: 0.00010987074922061689
INFO:root:Entering gradient accumulation loop for step 1240
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0267, Head Loss: 0.1558
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0409, Head Loss: 0.1728
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0444, Head Loss: 0.1327
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0503, Head Loss: 0.1550
INFO:root:Final accum gradient norm after all heads: 0.0503, Total Loss: 19.7208, Average Loss: 4.9302
INFO:root:Step 1241, Learning Rate: 0.00010964712138624765
INFO:root:Entering gradient accumulation loop for step 1241
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0206, Head Loss: 0.1490
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0267, Head Loss: 0.1220
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0370, Head Loss: 0.1602
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0445, Head Loss: 0.1596
INFO:root:Final accum gradient norm after all heads: 0.0445, Total Loss: 18.9048, Average Loss: 4.7262
INFO:root:Step 1242, Learning Rate: 0.00010942359019748225
INFO:root:Entering gradient accumulation loop for step 1242
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0206, Head Loss: 0.1664
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0321, Head Loss: 0.1677
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0383, Head Loss: 0.1724
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0452, Head Loss: 0.1563
INFO:root:Final accum gradient norm after all heads: 0.0452, Total Loss: 21.2130, Average Loss: 5.3033
INFO:root:Step 1243, Learning Rate: 0.00010920015618968045
INFO:root:Entering gradient accumulation loop for step 1243
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0252, Head Loss: 0.1899
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0334, Head Loss: 0.1752
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0429, Head Loss: 0.1727
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0511, Head Loss: 0.1829
INFO:root:Final accum gradient norm after all heads: 0.0511, Total Loss: 23.0620, Average Loss: 5.7655
INFO:root:Step 1244, Learning Rate: 0.00010897681989796927
INFO:root:Entering gradient accumulation loop for step 1244
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0190, Head Loss: 0.1494
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0410, Head Loss: 0.1687
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0504, Head Loss: 0.1954
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0543, Head Loss: 0.1614
INFO:root:Final accum gradient norm after all heads: 0.0543, Total Loss: 21.5987, Average Loss: 5.3997
INFO:root:Step 1245, Learning Rate: 0.00010875358185724158
INFO:root:Entering gradient accumulation loop for step 1245
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0215, Head Loss: 0.1861
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0372, Head Loss: 0.1774
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0410, Head Loss: 0.1633
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0453, Head Loss: 0.1568
INFO:root:Final accum gradient norm after all heads: 0.0453, Total Loss: 21.8759, Average Loss: 5.4690
INFO:root:Step 1246, Learning Rate: 0.00010853044260215507
INFO:root:Entering gradient accumulation loop for step 1246
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0290, Head Loss: 0.1877
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0372, Head Loss: 0.1384
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0449, Head Loss: 0.1761
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0542, Head Loss: 0.1829
INFO:root:Final accum gradient norm after all heads: 0.0542, Total Loss: 21.9221, Average Loss: 5.4805
INFO:root:Step 1247, Learning Rate: 0.00010830740266713087
INFO:root:Entering gradient accumulation loop for step 1247
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0246, Head Loss: 0.1611
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0381, Head Loss: 0.1795
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0440, Head Loss: 0.1448
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0504, Head Loss: 0.1938
INFO:root:Final accum gradient norm after all heads: 0.0504, Total Loss: 21.7351, Average Loss: 5.4338
INFO:root:Step 1248, Learning Rate: 0.00010808446258635207
INFO:root:Entering gradient accumulation loop for step 1248
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0288, Head Loss: 0.1726
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0378, Head Loss: 0.1741
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0467, Head Loss: 0.1791
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0512, Head Loss: 0.1483
INFO:root:Final accum gradient norm after all heads: 0.0512, Total Loss: 21.5721, Average Loss: 5.3930
INFO:root:Step 1249, Learning Rate: 0.00010786162289376271
INFO:root:Entering gradient accumulation loop for step 1249
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0246, Head Loss: 0.1747
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0304, Head Loss: 0.1559
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0360, Head Loss: 0.1541
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0403, Head Loss: 0.1568
INFO:root:Final accum gradient norm after all heads: 0.0403, Total Loss: 20.5284, Average Loss: 5.1321
INFO:root:Step 1250, Learning Rate: 0.0001076388841230664
INFO:root:Entering gradient accumulation loop for step 1250
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0214, Head Loss: 0.1625
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0272, Head Loss: 0.1614
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0387, Head Loss: 0.1593
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0462, Head Loss: 0.1881
INFO:root:Final accum gradient norm after all heads: 0.0462, Total Loss: 21.4805, Average Loss: 5.3701
INFO:root:Step 1250: Loss 5.37, Norm: 2.3596, Time: 44.05s, Tokens Seen: 317.5M
INFO:root:Step 1251, Learning Rate: 0.00010741624680772515
INFO:root:Entering gradient accumulation loop for step 1251
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0228, Head Loss: 0.1449
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0340, Head Loss: 0.1629
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0431, Head Loss: 0.1686
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0513, Head Loss: 0.1787
INFO:root:Final accum gradient norm after all heads: 0.0513, Total Loss: 20.9656, Average Loss: 5.2414
INFO:root:Step 1252, Learning Rate: 0.00010719371148095767
INFO:root:Entering gradient accumulation loop for step 1252
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0270, Head Loss: 0.1876
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0385, Head Loss: 0.1725
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0478, Head Loss: 0.1796
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0587, Head Loss: 0.1919
INFO:root:Final accum gradient norm after all heads: 0.0587, Total Loss: 23.4109, Average Loss: 5.8527
INFO:root:Step 1253, Learning Rate: 0.00010697127867573872
INFO:root:Entering gradient accumulation loop for step 1253
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0222, Head Loss: 0.1523
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0307, Head Loss: 0.1492
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0404, Head Loss: 0.1695
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0479, Head Loss: 0.1695
INFO:root:Final accum gradient norm after all heads: 0.0479, Total Loss: 20.4962, Average Loss: 5.1241
INFO:root:Step 1254, Learning Rate: 0.00010674894892479738
INFO:root:Entering gradient accumulation loop for step 1254
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0303, Head Loss: 0.1871
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0384, Head Loss: 0.1351
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0515, Head Loss: 0.2040
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0546, Head Loss: 0.1525
INFO:root:Final accum gradient norm after all heads: 0.0546, Total Loss: 21.7162, Average Loss: 5.4290
INFO:root:Step 1255, Learning Rate: 0.00010652672276061594
INFO:root:Entering gradient accumulation loop for step 1255
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0276, Head Loss: 0.1848
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0379, Head Loss: 0.1828
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0478, Head Loss: 0.1696
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0549, Head Loss: 0.1893
INFO:root:Final accum gradient norm after all heads: 0.0549, Total Loss: 23.2512, Average Loss: 5.8128
INFO:root:Step 1256, Learning Rate: 0.00010630460071542856
INFO:root:Entering gradient accumulation loop for step 1256
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0312, Head Loss: 0.1732
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0392, Head Loss: 0.1913
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0499, Head Loss: 0.1952
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0554, Head Loss: 0.1620
INFO:root:Final accum gradient norm after all heads: 0.0554, Total Loss: 23.0959, Average Loss: 5.7740
INFO:root:Step 1257, Learning Rate: 0.00010608258332122018
INFO:root:Entering gradient accumulation loop for step 1257
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0237, Head Loss: 0.1481
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0338, Head Loss: 0.1768
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0407, Head Loss: 0.1635
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0460, Head Loss: 0.1662
INFO:root:Final accum gradient norm after all heads: 0.0460, Total Loss: 20.9495, Average Loss: 5.2374
INFO:root:Step 1258, Learning Rate: 0.00010586067110972482
INFO:root:Entering gradient accumulation loop for step 1258
INFO:root:Final Micro-step 32, Gradient norm for MTP head 4: 0.0208, Head Loss: 0.1461
INFO:root:Final Micro-step 32, Gradient norm for MTP head 3: 0.0330, Head Loss: 0.1785
INFO:root:Final Micro-step 32, Gradient norm for MTP head 2: 0.0397, Head Loss: 0.1715
INFO:root:Final Micro-step 32, Gradient norm for MTP head 1: 0.0449, Head Loss: 0.1657
